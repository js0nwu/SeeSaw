{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<a href=\"javascript:code_toggle()\">Toggle Input Blocks</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<a href=\"javascript:code_toggle()\">Toggle Input Blocks</a>.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random as rand\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint as pp\n",
    "import matplotlib.pyplot as pplot\n",
    "import os\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from matplotlib import rcParams\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy import signal\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import linregress\n",
    "import scipy.integrate as integrate\n",
    "import shutil\n",
    "from scipy.signal import detrend\n",
    "from scipy.signal import correlate\n",
    "from scipy.signal import resample\n",
    "from scipy import signal\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def magv(v):\n",
    "    return np.sqrt(v.dot(v))\n",
    "def tupleStat(tupleList, meanMode=False):\n",
    "    leftTuples = tupleList[:,0]\n",
    "    rightTuples = tupleList[:,1]\n",
    "    if meanMode:\n",
    "        leftMean = np.mean(leftTuples)\n",
    "        rightMean = np.mean(rightTuples)\n",
    "        diffMean = leftMean - rightMean\n",
    "        return diffMean\n",
    "    else:\n",
    "        diffs = [leftTuples[i] - rightTuples[i] for i in range(len(leftTuples))]\n",
    "        return np.std(np.array(diffs))\n",
    "\n",
    "def tupleStatCombine(tupleList, meanMode=False, projectLeft=False):\n",
    "    leftTuples = tupleList[:,0]\n",
    "    rightTuples = tupleList[:,1]\n",
    "    leftTuples = np.array(leftTuples)\n",
    "    rightTuples = np.array(rightTuples)\n",
    "    if meanMode:\n",
    "        lt = leftTuples.mean(axis=0)\n",
    "        rt = rightTuples.mean(axis=0)\n",
    "        dotp = lt.dot(rt)/(magv(lt) if projectLeft else magv(rt))\n",
    "        return dotp\n",
    "    else:\n",
    "        lt = leftTuples.std(axis=0)\n",
    "        rt = rightTuples.std(axis=0)\n",
    "        dotp = lt.dot(rt)/(magv(lt) if projectLeft else magv(rt))\n",
    "        return dotp\n",
    "    \n",
    "def flip2Tuple(t):\n",
    "    return (t[1], t[0])\n",
    "\n",
    "def itemFlipper(tupleList, flipList):\n",
    "    newList = []\n",
    "    for i in range(len(tupleList)):\n",
    "        if flipList[i]:\n",
    "            newList.append(flip2Tuple(tupleList[i]))\n",
    "        else:\n",
    "            newList.append(tupleList[i])\n",
    "    return newList\n",
    "            \n",
    "\n",
    "def comboIterator(tupleList):\n",
    "    tupleLength = len(tupleList)\n",
    "    combos = []\n",
    "    for i in range(2**tupleLength-1):\n",
    "        numerical = i+1\n",
    "        flipList = [True if d == '1' else False for d in \"{0:b}\".format(numerical).zfill(tupleLength)]\n",
    "        combos.append(itemFlipper(tupleList, flipList))\n",
    "    return combos\n",
    "\n",
    "def mag(x, y, z):\n",
    "    return np.sqrt(x**2 + y**2 + z**2)\n",
    "\n",
    "def plot_distribution(ax, data, bins, actual=None, color=\"blue\", drawStds=3, vlines=None, vlinesColor=\"black\", xLabel=\"x\", yLabel=\"y\", title=\"Title\"):\n",
    "    sns.distplot(data, rug=True, bins=bins, color=color, ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xLabel)\n",
    "    ax.set_ylabel(yLabel)\n",
    "    if actual is not None:\n",
    "        ax.axvline(x=actual, color=vlinesColor, linewidth=2, clip_on=False)\n",
    "    if vlines is not None:\n",
    "        for vline in vlines:\n",
    "            ax.axvline(x=vline, color=vlinesColor, linewidth=0.5, linestyle=\"dashed\")\n",
    "    if drawStds > 0:\n",
    "        for i in range(drawStds):\n",
    "            stdLine = i + 1\n",
    "            ax.axvline(x=np.mean(np.array(data)) - np.std(np.array(data)) * stdLine, linestyle=\"dashed\", linewidth=0.5, color=color)\n",
    "            ax.axvline(x=np.mean(np.array(data)) + np.std(np.array(data)) * stdLine, linestyle=\"dashed\", linewidth=0.5, color=color)\n",
    "    ax.axvline(x=np.mean(data), color=color, linewidth=1)\n",
    "\n",
    "def diff_csv(csvData, rightMinusLeft=False):\n",
    "    output = csvData.copy()\n",
    "    lbx = 0\n",
    "    lby = 0\n",
    "    lbz = 0\n",
    "    if rightMinusLeft:\n",
    "        for i in range(len(csvData['lx'])):\n",
    "            dax = csvData['rx'][i] - lbx\n",
    "            day = csvData['ry'][i] - lby\n",
    "            daz = csvData['rz'][i] - lbz\n",
    "            dbx = csvData['lx'][i] - csvData['rx'][i]\n",
    "            dby = csvData['ly'][i] - csvData['ry'][i]\n",
    "            dbz = csvData['lz'][i] - csvData['rz'][i]\n",
    "            lbx = csvData['lx'][i]\n",
    "            lby = csvData['ly'][i]\n",
    "            lbz = csvData['lz'][i]\n",
    "            ddx = dbx - dax\n",
    "            ddy = dby - day\n",
    "            ddz = dbz - daz\n",
    "            if i == 0:\n",
    "                continue\n",
    "            output['rx'][i] = dax\n",
    "            output['ry'][i] = day\n",
    "            output['rz'][i] = daz\n",
    "            output['lx'][i] = dbx\n",
    "            output['ly'][i] = dby\n",
    "            output['lz'][i] = dbz\n",
    "            output['dx'][i] = ddx\n",
    "            output['dy'][i] = ddy\n",
    "            output['dz'][i] = ddz\n",
    "    else:\n",
    "        for i in range(len(csvData['lx'])):\n",
    "            dax = -csvData['rx'][i] + lbx\n",
    "            day = -csvData['ry'][i] + lby\n",
    "            daz = -csvData['rz'][i] + lbz\n",
    "            dbx = -csvData['lx'][i] + csvData['rx'][i]\n",
    "            dby = -csvData['ly'][i] + csvData['ry'][i]\n",
    "            dbz = -csvData['lz'][i] + csvData['rz'][i]\n",
    "            lbx = csvData['lx'][i]\n",
    "            lby = csvData['ly'][i]\n",
    "            lbz = csvData['lz'][i]\n",
    "            ddx = dbx - dax\n",
    "            ddy = dby - day\n",
    "            ddz = dbz - daz\n",
    "            if i == 0:\n",
    "                continue\n",
    "            output['rx'][i] = dax\n",
    "            output['ry'][i] = day\n",
    "            output['rz'][i] = daz\n",
    "            output['lx'][i] = dbx\n",
    "            output['ly'][i] = dby\n",
    "            output['lz'][i] = dbz\n",
    "            output['dx'][i] = ddx\n",
    "            output['dy'][i] = ddy\n",
    "            output['dz'][i] = ddz\n",
    "    return output\n",
    "\n",
    "def get_ewma(df, alpha=1):\n",
    "    # Compute alpha and exponential moving average\n",
    "    span = (2-alpha)/alpha\n",
    "    df_smooth = pd.ewma(df, span=span, adjust=False)\n",
    "    return df_smooth\n",
    "\n",
    "def data_kde(data):\n",
    "    return gaussian_kde(data, bw_method=\"scott\")\n",
    "\n",
    "def data_grid(data, kde, bw=\"scotts\", cut=3, gridsize=500):\n",
    "    adata = np.array(data)\n",
    "    bw = getattr(kde, \"%s_factor\" % bw)() * np.std(adata)\n",
    "    clip = (-np.inf, np.inf)\n",
    "    support_min = max(adata.min() - bw * cut, clip[0])\n",
    "    support_max = min(adata.max() + bw * cut, clip[1])\n",
    "    return np.linspace(support_min, support_max, gridsize)\n",
    "\n",
    "def univariate_kde(data):\n",
    "    data = np.array(data)\n",
    "    dkde = data_kde(data)\n",
    "    dgrid = data_grid(data, dkde)\n",
    "    return (dgrid, dkde)\n",
    "\n",
    "def kde_intersect(u1, u2, middle_factor=0.1):\n",
    "    d1 = u1[0]\n",
    "    d2 = u2[0]\n",
    "    d1a = d1.min()\n",
    "    d1b = d1.max()\n",
    "    d2a = d2.min()\n",
    "    d2b = d2.max()\n",
    "    if d1b < d2a or d2b < d1a:\n",
    "        return None\n",
    "    if d1a < d2a:\n",
    "        db = (d2a, d1b)\n",
    "    else:\n",
    "        db = (d1a, d2b)\n",
    "    ds = [x for x in np.concatenate((d1, d2)) if x >= db[0] and x <= db[1]]\n",
    "    dslen = max(ds) - min(ds)\n",
    "    ds = np.array([x for x in ds if x >= db[0] + middle_factor * dslen and x <= db[1] - middle_factor * dslen])\n",
    "    kde1 = u1[1]\n",
    "    kde2 = u2[1]\n",
    "    diffs = np.abs(kde1(ds) - kde2(ds))\n",
    "    mindiff = ds[np.argmin(diffs)]\n",
    "    return (mindiff, db[0], db[1])\n",
    "    \n",
    "def distribution_accuracy(q, d):\n",
    "    i = kde_intersect(q, d)\n",
    "    if i is None:\n",
    "        return (0, 0, 0)\n",
    "    if q[0].min() < d[0].min():\n",
    "        a = integrate.quad(d[1], i[1], i[0])[0]\n",
    "        b = integrate.quad(q[1], i[0], i[2])[0]\n",
    "        return (a + b, a, b)\n",
    "    else:\n",
    "        a = integrate.quad(q[1], i[1], i[0])[0]\n",
    "        b = integrate.quad(d[1], i[0], i[2])[0]\n",
    "        return (a + b, a, b)\n",
    "\n",
    "def remove_trend(x):\n",
    "    return detrend(x)\n",
    "\n",
    "#http://stackoverflow.com/a/4690225\n",
    "def find_timeshift(a, b):\n",
    "    shiftFactor = a.size - 1\n",
    "    correlateIndex = np.argmax(correlate(a, b))\n",
    "    return shiftFactor - correlateIndex\n",
    "\n",
    "def duty_function_permutation(permutation, repeat):\n",
    "    d = []\n",
    "    for p in permutation:\n",
    "        d.extend([p] * repeat)\n",
    "    return np.array(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# peak detection code taken from https://gist.github.com/sixtenbe/1178136\n",
    "\n",
    "def _datacheck_peakdetect(x_axis, y_axis):\n",
    "    if x_axis is None:\n",
    "        x_axis = range(len(y_axis))\n",
    "    \n",
    "    if len(y_axis) != len(x_axis):\n",
    "        raise ValueError( \n",
    "                \"Input vectors y_axis and x_axis must have same length\")\n",
    "    \n",
    "    #needs to be a numpy array\n",
    "    y_axis = np.array(y_axis)\n",
    "    x_axis = np.array(x_axis)\n",
    "    return x_axis, y_axis\n",
    "\n",
    "def peakdetect(y_axis, x_axis = None, lookahead = 200, delta=0):\n",
    "    \"\"\"\n",
    "    Converted from/based on a MATLAB script at: \n",
    "    http://billauer.co.il/peakdet.html\n",
    "    \n",
    "    function for detecting local maxima and minima in a signal.\n",
    "    Discovers peaks by searching for values which are surrounded by lower\n",
    "    or larger values for maxima and minima respectively\n",
    "    \n",
    "    keyword arguments:\n",
    "    y_axis -- A list containing the signal over which to find peaks\n",
    "    \n",
    "    x_axis -- A x-axis whose values correspond to the y_axis list and is used\n",
    "        in the return to specify the position of the peaks. If omitted an\n",
    "        index of the y_axis is used.\n",
    "        (default: None)\n",
    "    \n",
    "    lookahead -- distance to look ahead from a peak candidate to determine if\n",
    "        it is the actual peak\n",
    "        (default: 200) \n",
    "        '(samples / period) / f' where '4 >= f >= 1.25' might be a good value\n",
    "    \n",
    "    delta -- this specifies a minimum difference between a peak and\n",
    "        the following points, before a peak may be considered a peak. Useful\n",
    "        to hinder the function from picking up false peaks towards to end of\n",
    "        the signal. To work well delta should be set to delta >= RMSnoise * 5.\n",
    "        (default: 0)\n",
    "            When omitted delta function causes a 20% decrease in speed.\n",
    "            When used Correctly it can double the speed of the function\n",
    "    \n",
    "    \n",
    "    return: two lists [max_peaks, min_peaks] containing the positive and\n",
    "        negative peaks respectively. Each cell of the lists contains a tuple\n",
    "        of: (position, peak_value) \n",
    "        to get the average peak value do: np.mean(max_peaks, 0)[1] on the\n",
    "        results to unpack one of the lists into x, y coordinates do: \n",
    "        x, y = zip(*max_peaks)\n",
    "    \"\"\"\n",
    "    max_peaks = []\n",
    "    min_peaks = []\n",
    "    dump = []   #Used to pop the first hit which almost always is false\n",
    "       \n",
    "    # check input data\n",
    "    x_axis, y_axis = _datacheck_peakdetect(x_axis, y_axis)\n",
    "    # store data length for later use\n",
    "    length = len(y_axis)\n",
    "    \n",
    "    \n",
    "    #perform some checks\n",
    "    if lookahead < 1:\n",
    "        raise ValueError(\"Lookahead must be '1' or above in value\")\n",
    "    if not (np.isscalar(delta) and delta >= 0):\n",
    "        raise ValueError(\"delta must be a positive number\")\n",
    "    \n",
    "    #maxima and minima candidates are temporarily stored in\n",
    "    #mx and mn respectively\n",
    "    mn, mx = np.Inf, -np.Inf\n",
    "    \n",
    "    #Only detect peak if there is 'lookahead' amount of points after it\n",
    "    for index, (x, y) in enumerate(zip(x_axis[:-lookahead], \n",
    "                                        y_axis[:-lookahead])):\n",
    "        if y > mx:\n",
    "            mx = y\n",
    "            mxpos = x\n",
    "        if y < mn:\n",
    "            mn = y\n",
    "            mnpos = x\n",
    "        \n",
    "        ####look for max####\n",
    "        if y < mx-delta and mx != np.Inf:\n",
    "            #Maxima peak candidate found\n",
    "            #look ahead in signal to ensure that this is a peak and not jitter\n",
    "            if y_axis[index:index+lookahead].max() < mx:\n",
    "                max_peaks.append([mxpos, mx])\n",
    "                dump.append(True)\n",
    "                #set algorithm to only find minima now\n",
    "                mx = np.Inf\n",
    "                mn = np.Inf\n",
    "                if index+lookahead >= length:\n",
    "                    #end is within lookahead no more peaks can be found\n",
    "                    break\n",
    "                continue\n",
    "            #else:  #slows shit down this does\n",
    "            #    mx = ahead\n",
    "            #    mxpos = x_axis[np.where(y_axis[index:index+lookahead]==mx)]\n",
    "        \n",
    "        ####look for min####\n",
    "        if y > mn+delta and mn != -np.Inf:\n",
    "            #Minima peak candidate found \n",
    "            #look ahead in signal to ensure that this is a peak and not jitter\n",
    "            if y_axis[index:index+lookahead].min() > mn:\n",
    "                min_peaks.append([mnpos, mn])\n",
    "                dump.append(False)\n",
    "                #set algorithm to only find maxima now\n",
    "                mn = -np.Inf\n",
    "                mx = -np.Inf\n",
    "                if index+lookahead >= length:\n",
    "                    #end is within lookahead no more peaks can be found\n",
    "                    break\n",
    "            #else:  #slows shit down this does\n",
    "            #    mn = ahead\n",
    "            #    mnpos = x_axis[np.where(y_axis[index:index+lookahead]==mn)]\n",
    "    \n",
    "    \n",
    "    #Remove the false hit on the first value of the y_axis\n",
    "    try:\n",
    "        if dump[0]:\n",
    "            max_peaks.pop(0)\n",
    "        else:\n",
    "            min_peaks.pop(0)\n",
    "        del dump\n",
    "    except IndexError:\n",
    "        #no peaks were found, should the function return empty lists?\n",
    "        pass\n",
    "        \n",
    "    return [max_peaks, min_peaks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(color_codes=True)\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "FIGURE_SIZE = (15, 15)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MEAN_GRAPH = False\n",
    "WINDOWS = False\n",
    "FILE_FORMAT = \".pdf\"\n",
    "FOLDER_PREFIX = \"./figures/\"\n",
    "\n",
    "TAP_ACCEPT_THRESHOLD = 2.0\n",
    "CORRELATION_ACCEPT_THRESHOLD = 0.7\n",
    "\n",
    "pairNum = 4\n",
    "\n",
    "alphaFactors = {\"magnet\":1, \"accel\":0.02, \"gyro\":0.003}\n",
    "\n",
    "START_PADDING = 0.1\n",
    "END_PADDING = 0.1\n",
    "\n",
    "SAMPLING_PERIOD = 10\n",
    "SAMPLING_WINDOW = 400\n",
    "\n",
    "SHOW_CORRELATION_WINDOWS = False\n",
    "CORRELATION_EWMA = False\n",
    "\n",
    "#CSV_FILE = \"/Users/jwpilly/Downloads/p2/person2/p2_e22_t1473881179945_scombinedMag.csv\"\n",
    "#CSV_FILE = \"/Users/jwpilly/Downloads/person2/p2_e46_t1473883589976_scombinedMag.csv\" # thumb 1000\n",
    "#CSV_FILE = \"/Users/jwpilly/Downloads/person2/p2_e51_t1473883981488_scombinedMag.csv\" # walk sync 750\n",
    "#CSV_FILE = \"/Users/jwpilly/Desktop/Flux/fast/p0_e1_t1475693199664_scombinedMag.csv\" # thumb 500\n",
    "#CSV_PATH = \"/Users/jwpilly/Desktop/Flux/fast2/\"\n",
    "#CSV_PATH = \"/media/jwpilly/PillowDisk/Research/Flux/Data/Testing/2016_10_05/\"\n",
    "#CSV_PATH = \"/Volumes/PillowDisk/Research/Flux/Data/Testing/2016_10_17/\"\n",
    "#CSV_PATH = \"/Volumes/PillowDisk/Research/Flux/Data/Testing/2016_10_19/\"\n",
    "CSV_PATH = \"/Volumes/PillowDisk/Research/Flux/Data/Testing/2016_11_08/\"\n",
    "#CSV_PATH = \"/media/jwpilly/PillowDisk/Research/Flux/Data/Study/p2/person2/\"\n",
    "#CSV_PATH = \"/media/jwpilly/PillowDisk/Research/Flux/Data/Testing/2016_10_19/\"\n",
    "#CSV_PATH = \"/Volumes/PillowDisk/Research/Flux/Data/Study/p2/person2/\"\n",
    "#CSV_PREFIX = \"p3_e11_t1476728813906\"\n",
    "#CSV_PREFIX = \"p3_e10_t1476728781628\"\n",
    "#CSV_PREFIX = \"p3_e12_t1476728844897\"\n",
    "\n",
    "CSV_PREFIX = \"p1_e5_t1476900096622\"\n",
    "CSV_NOISE_PREFIX = \"p1_e6_t1476900113453\"\n",
    "\n",
    "#CSV_PREFIX = \"p1_e4_t1476900582728\"\n",
    "#CSV_NOISE_PREFIX = \"p1_e7_t1476900637771\"\n",
    "\n",
    "#CSV_PREFIX = \"p1_e1_t1476900619565\" # thumb sync 750\n",
    "#CSV_NOISE_PREFIX = \"p1_e3_t1476900674888\" # still 750\n",
    "\n",
    "#CSV_PREFIX = \"p2_e51_t1473883981488\" # walk sync 750\n",
    "#CSV_NOISE_PREFIX = \"p2_e54_t1473884300213\" # walk noise 750\n",
    "\n",
    "#CSV_PREFIX = \"p2_e52_t1473884089535\" # thumb 1000\n",
    "#CSV_NOISE_PREFIX = \"p2_e49_t1473883813406\" # browse noise 1000\n",
    "\n",
    "CSV_MAG_SUFFIX = \"_scombinedMag.csv\"\n",
    "CSV_ACCEL_SUFFIX = \"_scombinedAccel.csv\"\n",
    "CSV_GYRO_SUFFIX = \"_scombinedGyro.csv\"\n",
    "CSV_SENSOR_SUFFIX = \"_ssensorData.csv\"\n",
    "\n",
    "USE_DELTAS = False\n",
    "USE_STD_ALGORITHM = True\n",
    "PLOT_SENSOR = \"magnet\"\n",
    "NOISE_PERMUTATION = False\n",
    "\n",
    "SAVE_FILES = False\n",
    "FILE_OUTPUT = False\n",
    "\n",
    "FIT_SQUARE = True\n",
    "\n",
    "def generate_filename(basename):\n",
    "    return FOLDER_PREFIX + CSV_PREFIX + \"_\" + ((\"\" if USE_DELTAS else \"d\") + (\"S\" if USE_STD_ALGORITHM else \"s\")) + \"_\" + PLOT_SENSOR + \"_\" + basename + FILE_FORMAT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generate_files():\n",
    "    csvData = csvSensorData\n",
    "    plotX = []\n",
    "    plotY = []\n",
    "    plotZ = []\n",
    "    plotMag = []\n",
    "    pplot.clf()\n",
    "    for rowI in range(len(csvData['sensor'])):\n",
    "        row = csvData['sensor'][rowI]\n",
    "        if row == PLOT_SENSOR:\n",
    "            x = csvData['x'][rowI]\n",
    "            y = csvData['y'][rowI]\n",
    "            z = csvData['z'][rowI]\n",
    "            t = csvData['time'][rowI]\n",
    "            plotX.append((t, x))\n",
    "            plotY.append((t, y))\n",
    "            plotZ.append((t, z))\n",
    "            plotMag.append((t, mag(x, y, z)))\n",
    "        elif row == 'left':\n",
    "            pplot.axvline(x=csvData['time'][rowI], color='red')\n",
    "        elif row == 'right':\n",
    "            pplot.axvline(x=csvData['time'][rowI], color='black')\n",
    "    plotX = np.array(plotX)\n",
    "    plotY = np.array(plotY)\n",
    "    plotZ = np.array(plotZ)\n",
    "    plotMag = np.array(plotMag)\n",
    "    pplot.plot(plotX[:,0], get_ewma(plotX[:,1], alphaFactors[PLOT_SENSOR]), color='red')\n",
    "    pplot.plot(plotY[:,0], get_ewma(plotY[:,1], alphaFactors[PLOT_SENSOR]), color='green')\n",
    "    pplot.plot(plotZ[:,0], get_ewma(plotZ[:,1], alphaFactors[PLOT_SENSOR]), color='blue')\n",
    "    pplot.plot(plotMag[:,0], get_ewma(plotMag[:,1], 1), color='turquoise')\n",
    "    pplot.savefig(generate_filename(\"raw_data\")) if SAVE_FILES else pplot.show()\n",
    "if not SAVE_FILES:\n",
    "    data_plot_raw_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable/Environment Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV_PREFIX p1_e5_t1476900096622\n"
     ]
    }
   ],
   "source": [
    "def initialize_environment():\n",
    "    print(\"CSV_PREFIX\", CSV_PREFIX)\n",
    "    global CSV_MAG_FILE\n",
    "    global CSV_ACCEL_FILE\n",
    "    global CSV_GYRO_FILE\n",
    "    global CSV_SENSOR_FILE\n",
    "    global CSV_NOISE_MAG_FILE\n",
    "    global CSV_NOISE_ACCEL_FILE\n",
    "    global CSV_NOISE_GYRO_FILE\n",
    "    global CSV_NOISE_SENSOR_FILE\n",
    "    CSV_MAG_FILE = CSV_PATH + CSV_PREFIX + CSV_MAG_SUFFIX\n",
    "    CSV_ACCEL_FILE = CSV_PATH + CSV_PREFIX + CSV_ACCEL_SUFFIX\n",
    "    CSV_GYRO_FILE = CSV_PATH + CSV_PREFIX + CSV_GYRO_SUFFIX\n",
    "    #CSV_SENSOR_FILE = CSV_PATH + CSV_PREFIX + CSV_SENSOR_SUFFIX\n",
    "    CSV_SENSOR_FILE = CSV_PATH + \"p1_t1478571248324_xbrowsing.csv\"\n",
    "    CSV_NOISE_MAG_FILE = CSV_PATH + CSV_NOISE_PREFIX + CSV_MAG_SUFFIX\n",
    "    CSV_NOISE_ACCEL_FILE = CSV_PATH + CSV_NOISE_PREFIX + CSV_ACCEL_SUFFIX\n",
    "    CSV_NOISE_GYRO_FILE = CSV_PATH + CSV_NOISE_PREFIX + CSV_GYRO_SUFFIX\n",
    "    CSV_NOISE_SENSOR_FILE = CSV_PATH + CSV_NOISE_PREFIX + CSV_SENSOR_SUFFIX\n",
    "    global csvMagData\n",
    "    global csvSensorData\n",
    "    global csvNoiseMagData\n",
    "    global csvNoiseSensorData\n",
    "    #csvMagData = pd.read_csv(CSV_MAG_FILE, names=['lx','ly','lz','rx','ry','rz','dx','dy','dz', ''])\n",
    "    csvSensorData = pd.read_csv(CSV_SENSOR_FILE, names=['time','sensor','x','y','z','timestamp',''])\n",
    "    #csvNoiseMagData = pd.read_csv(CSV_NOISE_MAG_FILE, names=['lx','ly','lz','rx','ry','rz','dx','dy','dz', ''])\n",
    "    #csvNoiseSensorData = pd.read_csv(CSV_NOISE_SENSOR_FILE, names=['time','sensor','x','y','z','timestamp',''])\n",
    "    if not os.path.exists(FOLDER_PREFIX):\n",
    "        os.mkdir(FOLDER_PREFIX)\n",
    "if not SAVE_FILES:\n",
    "    initialize_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csvMagData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-78c1413bbe3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mpplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dist_summary_mean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mSAVE_FILES\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSAVE_FILES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mdata_plot_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-78c1413bbe3b>\u001b[0m in \u001b[0;36mdata_plot_distribution\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_plot_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcsvData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsvMagData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_DELTAS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mcsvData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mxResults_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csvMagData' is not defined"
     ]
    }
   ],
   "source": [
    "def data_plot_distribution():\n",
    "    csvData = csvMagData\n",
    "    if USE_DELTAS:\n",
    "        csvData = diff_csv(csvData)\n",
    "    xResults_all = []\n",
    "    yResults_all = []\n",
    "    zResults_all = []\n",
    "    magResults_all = []\n",
    "    queryX_all = []\n",
    "    queryY_all = []\n",
    "    queryZ_all = []\n",
    "    queryMag_all = []\n",
    "    for window in range(len(csvData) - pairNum):\n",
    "        resultsX = []\n",
    "        resultsY = []\n",
    "        resultsZ = []\n",
    "        tupleListX = []\n",
    "        tupleListY = []\n",
    "        tupleListZ = []\n",
    "        for p in range(pairNum): # creates the tuples from the current window\n",
    "            tupleListX.append((csvData['lx'][window + p], csvData['rx'][window + p]))\n",
    "            tupleListY.append((csvData['ly'][window + p], csvData['ry'][window + p]))\n",
    "            tupleListZ.append((csvData['lz'][window + p], csvData['rz'][window + p]))\n",
    "        queryX = tupleStat(np.array(tupleListX), not USE_STD_ALGORITHM)\n",
    "        queryY = tupleStat(np.array(tupleListY), not USE_STD_ALGORITHM)\n",
    "        queryZ = tupleStat(np.array(tupleListZ), not USE_STD_ALGORITHM)\n",
    "        windowCombosX = comboIterator(tupleListX)\n",
    "        windowCombosY = comboIterator(tupleListY)\n",
    "        windowCombosZ = comboIterator(tupleListZ)\n",
    "        xResults_i = []\n",
    "        yResults_i = []\n",
    "        zResults_i = []\n",
    "        for i in windowCombosX:\n",
    "            xResults_i.append(tupleStat(np.array(i), not USE_STD_ALGORITHM))\n",
    "        for i in windowCombosY:\n",
    "            yResults_i.append(tupleStat(np.array(i), not USE_STD_ALGORITHM))\n",
    "        for i in windowCombosZ:\n",
    "            zResults_i.append(tupleStat(np.array(i), not USE_STD_ALGORITHM))\n",
    "        std_distance_x = np.std(xResults_i)\n",
    "        std_distance_y = np.std(yResults_i)\n",
    "        std_distance_z = np.std(zResults_i)\n",
    "        std_distance_mag = mag(std_distance_x, std_distance_y, std_distance_z)\n",
    "        query_mag = mag(queryX, queryY, queryZ)\n",
    "        results_i_mean_mag = mag(np.mean(xResults_i), np.mean(yResults_i), np.mean(zResults_i))\n",
    "        results_i_std_mag = mag(np.std(xResults_i), np.std(yResults_i), np.std(zResults_i))\n",
    "        magResults_i = [mag(xResults_i[i], yResults_i[i], zResults_i[i]) for i in range(len(xResults_i))]\n",
    "        if WINDOWS:\n",
    "            pplot.clf()\n",
    "            f, (ax1, ax2, ax3, ax4) = pplot.subplots(4)\n",
    "            f.set_size_inches(FIGURE_SIZE)\n",
    "            plot_distribution(ax1, xResults_i, 10, queryX, \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query X Distribution\")\n",
    "            plot_distribution(ax2, yResults_i, 10, queryY, \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Y Distribution\")\n",
    "            plot_distribution(ax3, zResults_i, 10, queryZ, \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Z Distribution\")\n",
    "            plot_distribution(ax4, magResults_i, 10, query_mag, \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Combined Axes Magnitude\")\n",
    "            pplot.savefig(generate_filename(\"dist_window\" + str(window))) if SAVE_FILES else pplot.show()\n",
    "\n",
    "        xResults_all.append(xResults_i)\n",
    "        yResults_all.append(yResults_i)\n",
    "        zResults_all.append(zResults_i)\n",
    "        magResults_all.append(magResults_i)\n",
    "        queryX_all.append(queryX)\n",
    "        queryY_all.append(queryY)\n",
    "        queryZ_all.append(queryZ)\n",
    "        queryMag_all.append(query_mag)\n",
    "\n",
    "    pplot.clf()\n",
    "    f, (ax1, ax2, ax3, ax4) = pplot.subplots(4)\n",
    "    f.set_size_inches(FIGURE_SIZE)\n",
    "    xResults = [item for sublist in xResults_all for item in sublist]\n",
    "    yResults = [item for sublist in yResults_all for item in sublist]\n",
    "    zResults = [item for sublist in zResults_all for item in sublist]\n",
    "    magResults = [item for sublist in magResults_all for item in sublist]\n",
    "    plot_distribution(ax1, xResults, 10, None, \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query X Distribution\")\n",
    "    plot_distribution(ax1, queryX_all, 10, None, \"green\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query X Distribution\")\n",
    "    plot_distribution(ax2, yResults, 10, None, \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Y Distribution\")\n",
    "    plot_distribution(ax2, queryY_all, 10, None, \"green\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Y Distribution\")\n",
    "    plot_distribution(ax3, zResults, 10, None, \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Z Distribution\")\n",
    "    plot_distribution(ax3, queryZ_all, 10, None, \"green\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Z Distribution\")\n",
    "    plot_distribution(ax4, magResults, 10, None, \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Combined Axes Magnitude\")\n",
    "    plot_distribution(ax4, queryMag_all, 10, None, \"green\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Combined Axes Magnitude\")\n",
    "    pplot.savefig(generate_filename(\"dist_summary_all\")) if SAVE_FILES else pplot.show()\n",
    "    if MEAN_GRAPH:\n",
    "        pplot.clf()\n",
    "        f, (ax1, ax2, ax3, ax4) = pplot.subplots(4)\n",
    "        f.set_size_inches(FIGURE_SIZE)\n",
    "        plot_distribution(ax1, np.mean(np.array(xResults_all), axis=0), 10, np.mean(np.array(queryX_all)), \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query X Distribution\")\n",
    "        plot_distribution(ax2, np.mean(np.array(yResults_all), axis=0), 10, np.mean(np.array(queryY_all)), \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Y Distribution\")\n",
    "        plot_distribution(ax3, np.mean(np.array(zResults_all), axis=0), 10, np.mean(np.array(queryZ_all)), \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Z Distribution\")\n",
    "        plot_distribution(ax4, np.mean(np.array(magResults_all), axis=0), 10, np.mean(np.array(queryMag_all)), \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Combined Axes Magnitude\")\n",
    "        pplot.savefig(generate_filename(\"dist_summary_mean\")) if SAVE_FILES else pplot.show()\n",
    "if not SAVE_FILES:\n",
    "    data_plot_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Query Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csvData = csvMagData\n",
    "if USE_DELTAS:\n",
    "    csvData = diff_csv(csvData)\n",
    "for window in range(len(csvData) - pairNum + 1):\n",
    "    resultsX = []\n",
    "    resultsY = []\n",
    "    resultsZ = []\n",
    "    tupleListX = []\n",
    "    tupleListY = []\n",
    "    tupleListZ = []\n",
    "    for p in range(pairNum): # creates the tuples from the current window\n",
    "        tupleListX.append((csvData['lx'][window + p], csvData['rx'][window + p]))\n",
    "        tupleListY.append((csvData['ly'][window + p], csvData['ry'][window + p]))\n",
    "        tupleListZ.append((csvData['lz'][window + p], csvData['rz'][window + p]))\n",
    "        \n",
    "    queryX = tupleStat(np.array(tupleListX), not USE_STD_ALGORITHM)\n",
    "    queryY = tupleStat(np.array(tupleListY), not USE_STD_ALGORITHM)\n",
    "    queryZ = tupleStat(np.array(tupleListZ), not USE_STD_ALGORITHM)\n",
    "    windowCombosX = comboIterator(tupleListX)\n",
    "    windowCombosY = comboIterator(tupleListY)\n",
    "    windowCombosZ = comboIterator(tupleListZ)\n",
    "    xResults_i = []\n",
    "    yResults_i = []\n",
    "    zResults_i = []\n",
    "    for i in windowCombosX:\n",
    "        xResults_i.append(tupleStat(np.array(i), not USE_STD_ALGORITHM))\n",
    "    for i in windowCombosY:\n",
    "        yResults_i.append(tupleStat(np.array(i), not USE_STD_ALGORITHM))\n",
    "    for i in windowCombosZ:\n",
    "        zResults_i.append(tupleStat(np.array(i), not USE_STD_ALGORITHM))\n",
    "    std_distance_x = np.std(xResults_i)\n",
    "    std_distance_y = np.std(yResults_i)\n",
    "    std_distance_z = np.std(zResults_i)\n",
    "    std_distance_mag = mag(std_distance_x, std_distance_y, std_distance_z)\n",
    "    query_mag = mag(queryX, queryY, queryZ)\n",
    "    results_i_mean_mag = mag(np.mean(xResults_i), np.mean(yResults_i), np.mean(zResults_i))\n",
    "    results_i_std_mag = mag(np.std(xResults_i), np.std(yResults_i), np.std(zResults_i))\n",
    "    magResults_i = [mag(xResults_i[i], yResults_i[i], zResults_i[i]) for i in range(len(xResults_i))]\n",
    "    queryDistance = abs((query_mag - results_i_mean_mag) / results_i_std_mag)\n",
    "    accept = queryDistance > TAP_ACCEPT_THRESHOLD\n",
    "    direction = \"left\" if csvData['ly'][window + p] - csvData['ry'][window + p] < 0 else \"right\"\n",
    "    print(\"query_mag\", query_mag, \"mean\", results_i_mean_mag, \"std\", results_i_std_mag, \"distance\", queryDistance, accept, \"direction\", direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Raw Sensor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_plot_raw_data():\n",
    "    csvData = csvSensorData\n",
    "    plotX = []\n",
    "    plotY = []\n",
    "    plotZ = []\n",
    "    plotMag = []\n",
    "    pplot.clf()\n",
    "    for rowI in range(len(csvData['sensor'])):\n",
    "        row = csvData['sensor'][rowI]\n",
    "        if row == PLOT_SENSOR:\n",
    "            x = csvData['x'][rowI]\n",
    "            y = csvData['y'][rowI]\n",
    "            z = csvData['z'][rowI]\n",
    "            t = csvData['time'][rowI]\n",
    "            plotX.append((t, x))\n",
    "            plotY.append((t, y))\n",
    "            plotZ.append((t, z))\n",
    "            plotMag.append((t, mag(x, y, z)))\n",
    "        elif row == 'left':\n",
    "            pplot.axvline(x=csvData['time'][rowI], color='red')\n",
    "        elif row == 'right':\n",
    "            pplot.axvline(x=csvData['time'][rowI], color='black')\n",
    "        elif row == 'vibrate':\n",
    "            pplot.axvline(x=csvData['time'][rowI], color='green')\n",
    "    plotX = np.array(plotX)\n",
    "    plotY = np.array(plotY)\n",
    "    plotZ = np.array(plotZ)\n",
    "    plotMag = np.array(plotMag)\n",
    "    pplot.plot(plotX[:,0], get_ewma(plotX[:,1], alphaFactors[PLOT_SENSOR]), color='red')\n",
    "    pplot.plot(plotY[:,0], get_ewma(plotY[:,1], alphaFactors[PLOT_SENSOR]), color='green')\n",
    "    pplot.plot(plotZ[:,0], get_ewma(plotZ[:,1], alphaFactors[PLOT_SENSOR]), color='blue')\n",
    "    pplot.plot(plotMag[:,0], get_ewma(plotMag[:,1], 1), color='turquoise')\n",
    "    pplot.savefig(generate_filename(\"raw_data\")) if SAVE_FILES else pplot.show()\n",
    "if not SAVE_FILES:\n",
    "    data_plot_raw_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Correlation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_xcorrelation_graph():\n",
    "    csvData = csvSensorData\n",
    "    plotX = []\n",
    "    plotY = []\n",
    "    plotZ = []\n",
    "    plotMag = []\n",
    "    leftEvents = []\n",
    "    rightEvents = []\n",
    "    sensorDataLength = len(csvData['sensor'])\n",
    "    startIndex = int(sensorDataLength * START_PADDING)\n",
    "    endIndex = int(sensorDataLength - (sensorDataLength * END_PADDING))\n",
    "    pplot.clf()\n",
    "    for rowI in range(startIndex, endIndex):\n",
    "        row = csvData['sensor'][rowI]\n",
    "        if row == PLOT_SENSOR:\n",
    "            x = csvData['x'][rowI]\n",
    "            y = csvData['y'][rowI]\n",
    "            z = csvData['z'][rowI]\n",
    "            t = csvData['time'][rowI]\n",
    "            plotX.append((t, x))\n",
    "            plotY.append((t, y))\n",
    "            plotZ.append((t, z))\n",
    "            plotMag.append((t, mag(x, y, z)))\n",
    "        elif row == 'left':\n",
    "            leftEvents.append(csvData['time'][rowI])\n",
    "        elif row == 'right':\n",
    "            rightEvents.append(csvData['time'][rowI])\n",
    "    plotX = np.array(plotX)\n",
    "    plotY = np.array(plotY)\n",
    "    plotZ = np.array(plotZ)\n",
    "    plotMag = np.array(plotMag)\n",
    "    plotS = plotMag\n",
    "    plotS[:,1] = get_ewma(plotS[:,1], alpha=0.1)\n",
    "    plotS[:,1] = remove_trend(plotS[:,1])\n",
    "    signal_range = plotS[:,0]\n",
    "    signal_period = rightEvents[1] - rightEvents[0]\n",
    "    reference_signal = signal.square((2*np.pi/signal_period)*signal_range + (1.57079633 - (2*np.pi/signal_period)*leftEvents[0])) if FIT_SQUARE else np.sin((2*np.pi/signal_period)*signal_range + (1.57079633 - (2*np.pi/signal_period)*leftEvents[0])) # arcsin(1)\n",
    "    rfactor = signal_range.size * 20\n",
    "    rs2 = resample(reference_signal, rfactor, t=signal_range)\n",
    "    ps2 = resample(plotS[:,1], rfactor, t=signal_range)\n",
    "    resample_time = (signal_range[-1] - signal_range[0]) / rfactor\n",
    "    rdiff = signal_range[-1] - signal_range[0]\n",
    "    resample_range = np.arange(-rdiff, rdiff, resample_time)[:-1]\n",
    "    rs2 = rs2[0]\n",
    "    ps2 = ps2[0]\n",
    "    a = rs2\n",
    "    v = ps2\n",
    "    a = (a - a.mean()) / (a.std() * a.size)\n",
    "    v = (v - v.mean()) / v.std()\n",
    "    plotX = np.array(resample_range)\n",
    "    plotY = correlate(a, v)\n",
    "    pplot.plot(plotX, plotY)\n",
    "    pplot.savefig(generate_filename(\"xcorrelation_plot\")) if SAVE_FILES else pplot.show()\n",
    "if not SAVE_FILES:\n",
    "    data_xcorrelation_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot and Calculate Input Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_lag_calculation():\n",
    "    csvData = csvSensorData\n",
    "    plotX = []\n",
    "    plotY = []\n",
    "    plotZ = []\n",
    "    plotMag = []\n",
    "    leftEvents = []\n",
    "    rightEvents = []\n",
    "    sensorDataLength = len(csvData['sensor'])\n",
    "    startIndex = int(sensorDataLength * START_PADDING)\n",
    "    endIndex = int(sensorDataLength - (sensorDataLength * END_PADDING))\n",
    "    pplot.clf()\n",
    "    for rowI in range(startIndex, endIndex):\n",
    "        row = csvData['sensor'][rowI]\n",
    "        if row == PLOT_SENSOR:\n",
    "            x = csvData['x'][rowI]\n",
    "            y = csvData['y'][rowI]\n",
    "            z = csvData['z'][rowI]\n",
    "            t = csvData['time'][rowI]\n",
    "            plotX.append((t, x))\n",
    "            plotY.append((t, y))\n",
    "            plotZ.append((t, z))\n",
    "            plotMag.append((t, mag(x, y, z)))\n",
    "        elif row == 'left':\n",
    "            leftEvents.append(csvData['time'][rowI])\n",
    "            pplot.axvline(x=csvData['time'][rowI], color='red')\n",
    "        elif row == 'right':\n",
    "            rightEvents.append(csvData['time'][rowI])\n",
    "            pplot.axvline(x=csvData['time'][rowI], color='black')\n",
    "    plotX = np.array(plotX)\n",
    "    plotY = np.array(plotY)\n",
    "    plotZ = np.array(plotZ)\n",
    "    plotMag = np.array(plotMag)\n",
    "    plotS = plotMag\n",
    "    plotS[:,1] = get_ewma(plotS[:,1], alpha=0.1)\n",
    "    plotS[:,1] = remove_trend(plotS[:,1])\n",
    "    pplot.plot(plotS[:,0], plotS[:,1])\n",
    "    signal_range = plotS[:,0]\n",
    "    signal_period = rightEvents[1] - rightEvents[0]\n",
    "    reference_signal = signal.square((2*np.pi/signal_period)*signal_range + (1.57079633 - (2*np.pi/signal_period)*leftEvents[0])) if FIT_SQUARE else np.sin((2*np.pi/signal_period)*signal_range + (1.57079633 - (2*np.pi/signal_period)*leftEvents[0])) # arcsin(1)\n",
    "    pplot.plot(signal_range, reference_signal + np.mean(plotS[:,1]), color='g', linewidth=0.5)\n",
    "    maxesData, minsData = peakdetect(plotS[:,1], plotS[:,0], lookahead=1, delta=1)\n",
    "    for m in minsData:\n",
    "        x ,y = m\n",
    "        pplot.plot(x,y,'ro')\n",
    "    combinedData = minsData\n",
    "    lags = []\n",
    "    for i in range(len(rightEvents)):\n",
    "        distances = [abs(rightEvents[i] - p[0]) for p in combinedData]\n",
    "        lags.append(min(distances))\n",
    "    print(\"lags\")\n",
    "    print(lags)\n",
    "    print(\"avg lag time \", np.mean(np.array(lags)))\n",
    "    lag_reference_signal = signal.square((2*np.pi/signal_period)*signal_range + (1.57079633 - (2*np.pi/signal_period)*(leftEvents[0]-np.mean(np.array(lags))))) if FIT_SQUARE else np.sin((2*np.pi/signal_period)*signal_range + (1.57079633 - (2*np.pi/signal_period)*(leftEvents[0]-np.mean(np.array(lags))))) # arcsin(1)\n",
    "    pplot.plot(signal_range, lag_reference_signal + np.mean(plotS[:,1]), color='blue', linewidth=0.5)\n",
    "    rfactor = signal_range.size * 2\n",
    "    rs2 = resample(reference_signal, rfactor, t=signal_range)\n",
    "    ps2 = resample(plotS[:,1], rfactor, t=signal_range)\n",
    "    ts2 = rs2[1]\n",
    "    rs2 = rs2[0]\n",
    "    ps2 = ps2[0]\n",
    "    resample_time = (signal_range[-1] - signal_range[0]) / rfactor\n",
    "    lag_factor = find_timeshift(rs2, ps2)\n",
    "    print(np.max(abs(correlate(rs2, ps2)))/ rfactor)\n",
    "    lag_time = resample_time * lag_factor\n",
    "    correlate_reference_signal = signal.square((2*np.pi/signal_period)*signal_range + (1.57079633 - (2*np.pi/signal_period)*(leftEvents[0]+lag_time))) if FIT_SQUARE else np.sin((2*np.pi/signal_period)*signal_range + (1.57079633 - (2*np.pi/signal_period)*(leftEvents[0]+lag_time))) # arcsin(1)\n",
    "    pplot.plot(signal_range, correlate_reference_signal + np.mean(plotS[:,1]), color='red', linewidth=0.5)\n",
    "    pplot.savefig(generate_filename(\"lags_plot\")) if SAVE_FILES else pplot.show()\n",
    "    print(\"correlation against reference, ref - lag, ref + max correlation\")\n",
    "    print(pearsonr(reference_signal,plotS[:,1]))\n",
    "    print(pearsonr(lag_reference_signal,plotS[:,1]))\n",
    "    print(pearsonr(correlate_reference_signal,plotS[:,1]))\n",
    "    \n",
    "if not SAVE_FILES:\n",
    "    data_lag_calculation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Online Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def data_correlation_graphs():\n",
    "    csvData = csvSensorData\n",
    "    valueX = []\n",
    "    valueY = []\n",
    "    valueZ = []\n",
    "    valueMag = []\n",
    "    leftEvents = []\n",
    "    rightEvents = []\n",
    "    sensorDataLength = len(csvData['sensor'])\n",
    "    startIndex = 0\n",
    "    endIndex = sensorDataLength\n",
    "    for rowI in range(startIndex, endIndex):\n",
    "        row = csvData['sensor'][rowI]\n",
    "        if row == PLOT_SENSOR:\n",
    "            x = csvData['x'][rowI]\n",
    "            y = csvData['y'][rowI]\n",
    "            z = csvData['z'][rowI]\n",
    "            t = csvData['time'][rowI]\n",
    "            valueX.append((t, x))\n",
    "            valueY.append((t, y))\n",
    "            valueZ.append((t, z))\n",
    "            valueMag.append((t, mag(x, y, z)))\n",
    "        elif row == 'left':\n",
    "            leftEvents.append(csvData['time'][rowI])\n",
    "        elif row == 'right':\n",
    "            rightEvents.append(csvData['time'][rowI])\n",
    "    valueX = np.array(valueX)\n",
    "    valueY = np.array(valueY)\n",
    "    valueZ = np.array(valueZ)\n",
    "    valueMag = np.array(valueMag)\n",
    "    signalPeriod = rightEvents[1] - rightEvents[0]\n",
    "    referenceSignal = lambda x : signal.square((2*np.pi/signalPeriod)*x + (1.57079633 - (2*np.pi/signalPeriod)*leftEvents[0])) if FIT_SQUARE else np.sin((2*np.pi/signalPeriod)*x + (1.57079633 - (2*np.pi/signalPeriod)*leftEvents[0])) # arcsin(1)\n",
    "    windowTime = signalPeriod * pairNum\n",
    "    valueS = valueMag\n",
    "    correlationCoefficients = []\n",
    "    for rowI in range(len(leftEvents) - pairNum):\n",
    "        startWindow = leftEvents[rowI]\n",
    "        endWindow = leftEvents[rowI + pairNum]\n",
    "        window = []\n",
    "        for v in valueS:\n",
    "            valueTime = v[0]\n",
    "            if valueTime >= startWindow and valueTime <= endWindow:\n",
    "                window.append(v)\n",
    "        window = np.array(window)\n",
    "        generatedSignal = referenceSignal(window[:,0])\n",
    "        actualSignal = remove_trend(window[:,1])\n",
    "        signal_range = window[:,0]\n",
    "        rfactor = signal_range.size * 2\n",
    "        rs2 = resample(generatedSignal, rfactor, t=signal_range)\n",
    "        ps2 = resample(actualSignal, rfactor, t=signal_range)\n",
    "        ts2 = rs2[1]\n",
    "        rs2 = rs2[0]\n",
    "        ps2 = ps2[0]\n",
    "        resample_time = (signal_range[-1] - signal_range[0]) / rfactor\n",
    "        lag_factor = find_timeshift(rs2, ps2)\n",
    "        lag_time = resample_time * lag_factor\n",
    "        generatedSignal = signal.square((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_time))) if FIT_SQUARE else np.sin((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_time))) # arcsin(1)\n",
    "        if CORRELATION_EWMA:\n",
    "            actualSignal = get_ewma(actualSignal, alpha=0.1)\n",
    "        cc = pearsonr(generatedSignal, actualSignal)\n",
    "        correlationCoefficients.append(cc)\n",
    "        print(\"correlation for window \", rowI)\n",
    "        print(cc[0])\n",
    "        if SHOW_CORRELATION_WINDOWS:\n",
    "            pplot.clf()\n",
    "            pplot.plot(window[:,0], window[:,1] - np.mean(window[:,1]), color=\"purple\")\n",
    "            pplot.plot(window[:,0], actualSignal)\n",
    "            pplot.plot(window[:,0], generatedSignal + np.mean(actualSignal))\n",
    "            for i in range(pairNum + 1):\n",
    "                pplot.axvline(x=leftEvents[rowI + i], color='red')\n",
    "            for i in range(pairNum + 1):\n",
    "                pplot.axvline(x=rightEvents[rowI + i], color='black')\n",
    "            pplot.savefig(generate_filename(\"correlate_window\" + str(rowI))) if SAVE_FILES else pplot.show()\n",
    "\n",
    "    correlationCoefficients = np.array(correlationCoefficients)\n",
    "    pplot.clf()\n",
    "    pplot.plot(correlationCoefficients[:,0])\n",
    "    pplot.savefig(generate_filename(\"correlate_window_summary\")) if SAVE_FILES else pplot.show()\n",
    "\n",
    "if not SAVE_FILES:    \n",
    "    data_correlation_graphs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_online_performance():\n",
    "    permutationSDScores = []\n",
    "    permutationSScores = []\n",
    "    permutationMDScores = []\n",
    "    permutationMScores = []\n",
    "    correlationScores = []\n",
    "\n",
    "    csvData = csvSensorData\n",
    "    valueX = []\n",
    "    valueY = []\n",
    "    valueZ = []\n",
    "    valueMag = []\n",
    "    leftEvents = []\n",
    "    rightEvents = []\n",
    "    sensorDataLength = len(csvData['sensor'])\n",
    "    startIndex = 0\n",
    "    endIndex = sensorDataLength\n",
    "    for rowI in range(startIndex, endIndex):\n",
    "        row = csvData['sensor'][rowI]\n",
    "        if row == PLOT_SENSOR:\n",
    "            x = csvData['x'][rowI]\n",
    "            y = csvData['y'][rowI]\n",
    "            z = csvData['z'][rowI]\n",
    "            t = csvData['time'][rowI]\n",
    "            valueX.append((t, x))\n",
    "            valueY.append((t, y))\n",
    "            valueZ.append((t, z))\n",
    "            valueMag.append((t, mag(x, y, z)))\n",
    "        elif row == 'left':\n",
    "            leftEvents.append(csvData['time'][rowI])\n",
    "        elif row == 'right':\n",
    "            rightEvents.append(csvData['time'][rowI])\n",
    "    valueX = np.array(valueX)\n",
    "    valueY = np.array(valueY)\n",
    "    valueZ = np.array(valueZ)\n",
    "    valueMag = np.array(valueMag)\n",
    "    signalPeriod = rightEvents[1] - rightEvents[0]\n",
    "    referenceSignal = lambda x : signal.square((2*np.pi/signalPeriod)*x + (-1.57079633 - (2*np.pi/signalPeriod)*leftEvents[0])) # arcsin(-1) if FIT_SQUARE else np.sin((2*np.pi/signalPeriod)*x + (-1.57079633 - (2*np.pi/signalPeriod)*leftEvents[0])) # arcsin(-1)\n",
    "    windowTime = signalPeriod * pairNum\n",
    "    valueS = valueX\n",
    "    for rowI in range(len(leftEvents) - pairNum):\n",
    "        startWindow = leftEvents[rowI]\n",
    "        endWindow = leftEvents[rowI + pairNum]\n",
    "        window = []\n",
    "        for v in valueS:\n",
    "            valueTime = v[0]\n",
    "            if valueTime >= startWindow and valueTime <= endWindow:\n",
    "                window.append(v)\n",
    "        window = np.array(window)\n",
    "        generatedSignal = referenceSignal(window[:,0])\n",
    "        actualSignal = remove_trend(window[:,1])\n",
    "        signal_range = window[:,0]\n",
    "        rfactor = (np.max(signal_range) - np.min(signal_range)) // signal_range.size\n",
    "        ts2 = resample(signal_range, rfactor)\n",
    "        rs2 = resample(generatedSignal, rfactor)\n",
    "        ps2 = resample(actualSignal, rfactor)\n",
    "        lag_factor = find_timeshift(rs2, ps2)\n",
    "        lag_time = rfactor * lag_factor\n",
    "        generatedSignal = signal.square((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_time))) if FIT_SQUARE else np.sin((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_time))) # arcsin(1)\n",
    "        if CORRELATION_EWMA:\n",
    "            actualSignal = get_ewma(actualSignal, alpha=0.1)\n",
    "        cc = pearsonr(generatedSignal, actualSignal)\n",
    "        score = abs(cc[0])\n",
    "        direction = \"left\" if cc[0] > 0 else \"right\"\n",
    "        correlationScores.append((score, direction))\n",
    "\n",
    "    csvData = csvMagData\n",
    "    csvData = diff_csv(csvData)\n",
    "    for window in range(len(csvData) - pairNum + 1):\n",
    "        resultsX = []\n",
    "        resultsY = []\n",
    "        resultsZ = []\n",
    "        tupleListX = []\n",
    "        tupleListY = []\n",
    "        tupleListZ = []\n",
    "        for p in range(pairNum):\n",
    "            tupleListX.append((csvData['lx'][window + p], csvData['rx'][window + p]))\n",
    "            tupleListY.append((csvData['ly'][window + p], csvData['ry'][window + p]))\n",
    "            tupleListZ.append((csvData['lz'][window + p], csvData['rz'][window + p]))\n",
    "\n",
    "        queryX = tupleStat(np.array(tupleListX), False)\n",
    "        queryY = tupleStat(np.array(tupleListY), False)\n",
    "        queryZ = tupleStat(np.array(tupleListZ), False)\n",
    "        windowCombosX = comboIterator(tupleListX)\n",
    "        windowCombosY = comboIterator(tupleListY)\n",
    "        windowCombosZ = comboIterator(tupleListZ)\n",
    "        xResults_i = []\n",
    "        yResults_i = []\n",
    "        zResults_i = []\n",
    "        for i in windowCombosX:\n",
    "            xResults_i.append(tupleStat(np.array(i), False))\n",
    "        for i in windowCombosY:\n",
    "            yResults_i.append(tupleStat(np.array(i), False))\n",
    "        for i in windowCombosZ:\n",
    "            zResults_i.append(tupleStat(np.array(i), False))\n",
    "        query_mag = mag(queryX, queryY, queryZ)\n",
    "        results_i_mean_mag = mag(np.mean(xResults_i), np.mean(yResults_i), np.mean(zResults_i))\n",
    "        results_i_std_mag = mag(np.std(xResults_i), np.std(yResults_i), np.std(zResults_i))\n",
    "        magResults_i = [mag(xResults_i[i], yResults_i[i], zResults_i[i]) for i in range(len(xResults_i))]\n",
    "        queryDistance = abs((query_mag - results_i_mean_mag) / results_i_std_mag)\n",
    "        direction = \"left\" if csvMagData['ly'][window + p] - csvMagData['ry'][window + p] < 0 else \"right\"\n",
    "        score = norm.cdf(queryDistance) - norm.cdf(-queryDistance)\n",
    "        permutationSDScores.append((score, direction))\n",
    "\n",
    "    csvData = csvMagData\n",
    "    for window in range(len(csvData) - pairNum + 1):\n",
    "        resultsX = []\n",
    "        resultsY = []\n",
    "        resultsZ = []\n",
    "        tupleListX = []\n",
    "        tupleListY = []\n",
    "        tupleListZ = []\n",
    "        for p in range(pairNum):\n",
    "            tupleListX.append((csvData['lx'][window + p], csvData['rx'][window + p]))\n",
    "            tupleListY.append((csvData['ly'][window + p], csvData['ry'][window + p]))\n",
    "            tupleListZ.append((csvData['lz'][window + p], csvData['rz'][window + p]))\n",
    "\n",
    "        queryX = tupleStat(np.array(tupleListX), False)\n",
    "        queryY = tupleStat(np.array(tupleListY), False)\n",
    "        queryZ = tupleStat(np.array(tupleListZ), False)\n",
    "        windowCombosX = comboIterator(tupleListX)\n",
    "        windowCombosY = comboIterator(tupleListY)\n",
    "        windowCombosZ = comboIterator(tupleListZ)\n",
    "        xResults_i = []\n",
    "        yResults_i = []\n",
    "        zResults_i = []\n",
    "        for i in windowCombosX:\n",
    "            xResults_i.append(tupleStat(np.array(i), False))\n",
    "        for i in windowCombosY:\n",
    "            yResults_i.append(tupleStat(np.array(i), False))\n",
    "        for i in windowCombosZ:\n",
    "            zResults_i.append(tupleStat(np.array(i), False))\n",
    "        std_distance_x = np.std(xResults_i)\n",
    "        std_distance_y = np.std(yResults_i)\n",
    "        std_distance_z = np.std(zResults_i)\n",
    "        std_distance_mag = mag(std_distance_x, std_distance_y, std_distance_z)\n",
    "        query_mag = mag(queryX, queryY, queryZ)\n",
    "        results_i_mean_mag = mag(np.mean(xResults_i), np.mean(yResults_i), np.mean(zResults_i))\n",
    "        results_i_std_mag = mag(np.std(xResults_i), np.std(yResults_i), np.std(zResults_i))\n",
    "        magResults_i = [mag(xResults_i[i], yResults_i[i], zResults_i[i]) for i in range(len(xResults_i))]\n",
    "        queryDistance = abs((query_mag - results_i_mean_mag) / results_i_std_mag)\n",
    "        direction = \"left\" if csvMagData['ly'][window + p] - csvMagData['ry'][window + p] < 0 else \"right\"\n",
    "        score = norm.cdf(queryDistance) - norm.cdf(-queryDistance)\n",
    "        permutationSScores.append((score, direction))\n",
    "\n",
    "    csvData = csvMagData\n",
    "    csvData = diff_csv(csvData)\n",
    "    for window in range(len(csvData) - pairNum + 1):\n",
    "        resultsX = []\n",
    "        resultsY = []\n",
    "        resultsZ = []\n",
    "        tupleListX = []\n",
    "        tupleListY = []\n",
    "        tupleListZ = []\n",
    "        for p in range(pairNum):\n",
    "            tupleListX.append((csvData['lx'][window + p], csvData['rx'][window + p]))\n",
    "            tupleListY.append((csvData['ly'][window + p], csvData['ry'][window + p]))\n",
    "            tupleListZ.append((csvData['lz'][window + p], csvData['rz'][window + p]))\n",
    "\n",
    "        queryX = tupleStat(np.array(tupleListX), True)\n",
    "        queryY = tupleStat(np.array(tupleListY), True)\n",
    "        queryZ = tupleStat(np.array(tupleListZ), True)\n",
    "        windowCombosX = comboIterator(tupleListX)\n",
    "        windowCombosY = comboIterator(tupleListY)\n",
    "        windowCombosZ = comboIterator(tupleListZ)\n",
    "        xResults_i = []\n",
    "        yResults_i = []\n",
    "        zResults_i = []\n",
    "        for i in windowCombosX:\n",
    "            xResults_i.append(tupleStat(np.array(i), True))\n",
    "        for i in windowCombosY:\n",
    "            yResults_i.append(tupleStat(np.array(i), True))\n",
    "        for i in windowCombosZ:\n",
    "            zResults_i.append(tupleStat(np.array(i), True))\n",
    "        std_distance_x = np.std(xResults_i)\n",
    "        std_distance_y = np.std(yResults_i)\n",
    "        std_distance_z = np.std(zResults_i)\n",
    "        std_distance_mag = mag(std_distance_x, std_distance_y, std_distance_z)\n",
    "        query_mag = mag(queryX, queryY, queryZ)\n",
    "        results_i_mean_mag = mag(np.mean(xResults_i), np.mean(yResults_i), np.mean(zResults_i))\n",
    "        results_i_std_mag = mag(np.std(xResults_i), np.std(yResults_i), np.std(zResults_i))\n",
    "        magResults_i = [mag(xResults_i[i], yResults_i[i], zResults_i[i]) for i in range(len(xResults_i))]\n",
    "        queryDistance = abs((query_mag - results_i_mean_mag) / results_i_std_mag)\n",
    "        direction = \"left\" if csvMagData['ly'][window + p] - csvMagData['ry'][window + p] < 0 else \"right\"\n",
    "        score = norm.cdf(queryDistance) - norm.cdf(-queryDistance)\n",
    "        permutationMDScores.append((score, direction))    \n",
    "\n",
    "    csvData = csvMagData\n",
    "    for window in range(len(csvData) - pairNum + 1):\n",
    "        resultsX = []\n",
    "        resultsY = []\n",
    "        resultsZ = []\n",
    "        tupleListX = []\n",
    "        tupleListY = []\n",
    "        tupleListZ = []\n",
    "        for p in range(pairNum):\n",
    "            tupleListX.append((csvData['lx'][window + p], csvData['rx'][window + p]))\n",
    "            tupleListY.append((csvData['ly'][window + p], csvData['ry'][window + p]))\n",
    "            tupleListZ.append((csvData['lz'][window + p], csvData['rz'][window + p]))\n",
    "\n",
    "        queryX = tupleStat(np.array(tupleListX), True)\n",
    "        queryY = tupleStat(np.array(tupleListY), True)\n",
    "        queryZ = tupleStat(np.array(tupleListZ), True)\n",
    "        windowCombosX = comboIterator(tupleListX)\n",
    "        windowCombosY = comboIterator(tupleListY)\n",
    "        windowCombosZ = comboIterator(tupleListZ)\n",
    "        xResults_i = []\n",
    "        yResults_i = []\n",
    "        zResults_i = []\n",
    "        for i in windowCombosX:\n",
    "            xResults_i.append(tupleStat(np.array(i), True))\n",
    "        for i in windowCombosY:\n",
    "            yResults_i.append(tupleStat(np.array(i), True))\n",
    "        for i in windowCombosZ:\n",
    "            zResults_i.append(tupleStat(np.array(i), True))\n",
    "        std_distance_x = np.std(xResults_i)\n",
    "        std_distance_y = np.std(yResults_i)\n",
    "        std_distance_z = np.std(zResults_i)\n",
    "        std_distance_mag = mag(std_distance_x, std_distance_y, std_distance_z)\n",
    "        query_mag = mag(queryX, queryY, queryZ)\n",
    "        results_i_mean_mag = mag(np.mean(xResults_i), np.mean(yResults_i), np.mean(zResults_i))\n",
    "        results_i_std_mag = mag(np.std(xResults_i), np.std(yResults_i), np.std(zResults_i))\n",
    "        magResults_i = [mag(xResults_i[i], yResults_i[i], zResults_i[i]) for i in range(len(xResults_i))]\n",
    "        queryDistance = abs((query_mag - results_i_mean_mag) / results_i_std_mag)\n",
    "        direction = \"left\" if csvMagData['ly'][window + p] - csvMagData['ry'][window + p] < 0 else \"right\"\n",
    "        score = norm.cdf(queryDistance) - norm.cdf(-queryDistance)\n",
    "        permutationMScores.append((score, direction))      \n",
    "\n",
    "    def printResultRow(row):\n",
    "        return \"{0:.4f}\".format(row[0]) + \" \" + (\"L\" if row[1] == \"left\" else \"R\")\n",
    "    print(\"online comparison scores\")\n",
    "    for i in range(len(correlationScores)):\n",
    "        print(\"c:\", printResultRow(correlationScores[i]), \"psd:\", printResultRow(permutationSDScores[i]), \"ps:\", printResultRow(permutationSScores[i]), \"pmd:\", printResultRow(permutationMDScores[i]), \"pm:\", printResultRow(permutationMScores[i]))\n",
    "\n",
    "    pplot.clf()\n",
    "    SCORE_DIRECTION = False\n",
    "    if SCORE_DIRECTION:\n",
    "        cGraph = [-x[0] if x[1] == \"left\" else x[0] for x in correlationScores]\n",
    "        psdGraph = [-x[0] if x[1] == \"left\" else x[0] for x in permutationSDScores]\n",
    "        psGraph = [-x[0] if x[1] == \"left\" else x[0] for x in permutationSScores]\n",
    "        pmdGraph = [-x[0] if x[1] == \"left\" else x[0] for x in permutationMDScores]\n",
    "        pmGraph = [-x[0] if x[1] == \"left\" else x[0] for x in permutationMScores]\n",
    "        pplot.plot(np.array(cGraph))\n",
    "        pplot.plot(np.array(psdGraph))\n",
    "        pplot.plot(np.array(psGraph))\n",
    "        pplot.plot(np.array(pmdGraph))\n",
    "        pplot.plot(np.array(pmGraph))\n",
    "    else:\n",
    "        correlationScores = np.array(correlationScores)\n",
    "        permutationSDScores = np.array(permutationSDScores)\n",
    "        permutationSScores = np.array(permutationSScores)\n",
    "        permutationMDScores = np.array(permutationMDScores)\n",
    "        permutationMScores = np.array(permutationMScores)\n",
    "        pplot.plot(correlationScores[:,0])\n",
    "        pplot.plot(permutationSDScores[:,0])\n",
    "        pplot.plot(permutationSScores[:,0])\n",
    "        pplot.plot(permutationMDScores[:,0])\n",
    "        pplot.plot(permutationMScores[:,0])\n",
    "\n",
    "    pplot.legend([\"Correlation\", \"Permutation Std. Dev. w/ Deltas\", \"Permutation Std. Dev.\", \"Permutation Mean w/ Deltas\", \"Permutation Mean\"])\n",
    "    pplot.savefig(generate_filename(\"online_comparison\")) if SAVE_FILES else pplot.show()\n",
    "\n",
    "if not SAVE_FILES:\n",
    "    data_online_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual, Permutation Test, Noise Distribution Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def data_distribution_comparison():\n",
    "    xResults_all = []\n",
    "    yResults_all = []\n",
    "    zResults_all = []\n",
    "    magResults_all = []\n",
    "    combineResults_all = []\n",
    "    queryX_all = []\n",
    "    queryY_all = []\n",
    "    queryZ_all = []\n",
    "    queryMag_all = []\n",
    "    queryCombine_all = []\n",
    "    xResults_all_noise = []\n",
    "    yResults_all_noise = []\n",
    "    zResults_all_noise = []\n",
    "    magResults_all_noise = []\n",
    "    combineResults_all_noise = []\n",
    "    queryX_all_noise = []\n",
    "    queryY_all_noise = []\n",
    "    queryZ_all_noise = []\n",
    "    queryMag_all_noise = []\n",
    "    queryCombine_all_noise = []\n",
    "\n",
    "    csvData = csvNoiseMagData\n",
    "    if USE_DELTAS:\n",
    "        csvData = diff_csv(csvData)\n",
    "    for window in range(len(csvData) - pairNum):\n",
    "        resultsX = []\n",
    "        resultsY = []\n",
    "        resultsZ = []\n",
    "        resultsCombine = []\n",
    "        tupleListX = []\n",
    "        tupleListY = []\n",
    "        tupleListZ = []\n",
    "        tupleListCombine = []\n",
    "        for p in range(pairNum): # creates the tuples from the current window\n",
    "            tx = (csvData['lx'][window + p], csvData['rx'][window + p])\n",
    "            ty = (csvData['ly'][window + p], csvData['ry'][window + p])\n",
    "            tz = (csvData['lz'][window + p], csvData['rz'][window + p])\n",
    "            tupleListX.append(tx)\n",
    "            tupleListY.append(ty)\n",
    "            tupleListZ.append(tz)\n",
    "            tupleListCombine.append(((tx[0],ty[0],tz[0]), (tx[1],ty[1],tz[1])))\n",
    "        queryX = tupleStat(np.array(tupleListX), not USE_STD_ALGORITHM)\n",
    "        queryY = tupleStat(np.array(tupleListY), not USE_STD_ALGORITHM)\n",
    "        queryZ = tupleStat(np.array(tupleListZ), not USE_STD_ALGORITHM)\n",
    "        queryCombine = tupleStatCombine(np.array(tupleListCombine), not USE_STD_ALGORITHM)\n",
    "        windowCombosX = comboIterator(tupleListX)\n",
    "        windowCombosY = comboIterator(tupleListY)\n",
    "        windowCombosZ = comboIterator(tupleListZ)\n",
    "        windowCombosCombine = comboIterator(tupleListCombine)\n",
    "        xResults_i = []\n",
    "        yResults_i = []\n",
    "        zResults_i = []\n",
    "        combineResults_i = []\n",
    "        for i in windowCombosX:\n",
    "            xResults_i.append(tupleStat(np.array(i), not USE_STD_ALGORITHM))\n",
    "        for i in windowCombosY:\n",
    "            yResults_i.append(tupleStat(np.array(i), not USE_STD_ALGORITHM))\n",
    "        for i in windowCombosZ:\n",
    "            zResults_i.append(tupleStat(np.array(i), not USE_STD_ALGORITHM))\n",
    "        for i in windowCombosCombine:\n",
    "            combineResults_i.append(tupleStatCombine(np.array(i), not USE_STD_ALGORITHM))\n",
    "        std_distance_x = np.std(xResults_i)\n",
    "        std_distance_y = np.std(yResults_i)\n",
    "        std_distance_z = np.std(zResults_i)\n",
    "        std_distance_combine = np.std(combineResults_i)\n",
    "        std_distance_mag = mag(std_distance_x, std_distance_y, std_distance_z)\n",
    "        query_mag = mag(queryX, queryY, queryZ)\n",
    "        query_combine = queryCombine\n",
    "        results_i_mean_mag = mag(np.mean(xResults_i), np.mean(yResults_i), np.mean(zResults_i))\n",
    "        results_i_std_mag = mag(np.std(xResults_i), np.std(yResults_i), np.std(zResults_i))\n",
    "        magResults_i = [mag(xResults_i[i], yResults_i[i], zResults_i[i]) for i in range(len(xResults_i))]\n",
    "        xResults_all_noise.append(xResults_i)\n",
    "        yResults_all_noise.append(yResults_i)\n",
    "        zResults_all_noise.append(zResults_i)\n",
    "        magResults_all_noise.append(magResults_i)\n",
    "        combineResults_all_noise.append(combineResults_i)\n",
    "        queryX_all_noise.append(queryX)\n",
    "        queryY_all_noise.append(queryY)\n",
    "        queryZ_all_noise.append(queryZ)\n",
    "        queryMag_all_noise.append(query_mag)\n",
    "        queryCombine_all_noise.append(query_combine)\n",
    "\n",
    "    csvData = csvMagData\n",
    "    if USE_DELTAS:\n",
    "        csvData = diff_csv(csvData)\n",
    "    for window in range(len(csvData) - pairNum):\n",
    "        resultsX = []\n",
    "        resultsY = []\n",
    "        resultsZ = []\n",
    "        resultsCombine = []\n",
    "        tupleListX = []\n",
    "        tupleListY = []\n",
    "        tupleListZ = []\n",
    "        tupleListCombine = []\n",
    "        for p in range(pairNum): # creates the tuples from the current window\n",
    "            tx = (csvData['lx'][window + p], csvData['rx'][window + p])\n",
    "            ty = (csvData['ly'][window + p], csvData['ry'][window + p])\n",
    "            tz = (csvData['lz'][window + p], csvData['rz'][window + p])\n",
    "            tupleListX.append(tx)\n",
    "            tupleListY.append(ty)\n",
    "            tupleListZ.append(tz)\n",
    "            tupleListCombine.append(((tx[0],ty[0],tz[0]), (tx[1],ty[1],tz[1])))\n",
    "        queryX = tupleStat(np.array(tupleListX), not USE_STD_ALGORITHM)\n",
    "        queryY = tupleStat(np.array(tupleListY), not USE_STD_ALGORITHM)\n",
    "        queryZ = tupleStat(np.array(tupleListZ), not USE_STD_ALGORITHM)\n",
    "        queryCombine = tupleStatCombine(np.array(tupleListCombine), not USE_STD_ALGORITHM)\n",
    "        windowCombosX = comboIterator(tupleListX)\n",
    "        windowCombosY = comboIterator(tupleListY)\n",
    "        windowCombosZ = comboIterator(tupleListZ)\n",
    "        windowCombosCombine = comboIterator(tupleListCombine)\n",
    "        xResults_i = []\n",
    "        yResults_i = []\n",
    "        zResults_i = []\n",
    "        combineResults_i = []\n",
    "        for i in windowCombosX:\n",
    "            xResults_i.append(tupleStat(np.array(i), not USE_STD_ALGORITHM))\n",
    "        for i in windowCombosY:\n",
    "            yResults_i.append(tupleStat(np.array(i), not USE_STD_ALGORITHM))\n",
    "        for i in windowCombosZ:\n",
    "            zResults_i.append(tupleStat(np.array(i), not USE_STD_ALGORITHM))\n",
    "        for i in windowCombosCombine:\n",
    "            combineResults_i.append(tupleStatCombine(np.array(i), not USE_STD_ALGORITHM))\n",
    "        std_distance_x = np.std(xResults_i)\n",
    "        std_distance_y = np.std(yResults_i)\n",
    "        std_distance_z = np.std(zResults_i)\n",
    "        std_distance_combine = np.std(combineResults_i)\n",
    "        std_distance_mag = mag(std_distance_x, std_distance_y, std_distance_z)\n",
    "        query_mag = mag(queryX, queryY, queryZ)\n",
    "        query_combine = queryCombine\n",
    "        results_i_mean_mag = mag(np.mean(xResults_i), np.mean(yResults_i), np.mean(zResults_i))\n",
    "        results_i_std_mag = mag(np.std(xResults_i), np.std(yResults_i), np.std(zResults_i))\n",
    "        magResults_i = [mag(xResults_i[i], yResults_i[i], zResults_i[i]) for i in range(len(xResults_i))]\n",
    "        xResults_all.append(xResults_i)\n",
    "        yResults_all.append(yResults_i)\n",
    "        zResults_all.append(zResults_i)\n",
    "        magResults_all.append(magResults_i)\n",
    "        combineResults_all.append(combineResults_i)\n",
    "        queryX_all.append(queryX)\n",
    "        queryY_all.append(queryY)\n",
    "        queryZ_all.append(queryZ)\n",
    "        queryMag_all.append(query_mag)\n",
    "        queryCombine_all.append(query_combine)\n",
    "    pplot.clf()\n",
    "    f, (ax1, ax2, ax3, ax4, ax5) = pplot.subplots(5)\n",
    "    f.set_size_inches(FIGURE_SIZE)\n",
    "    xResults = [item for sublist in xResults_all for item in sublist]\n",
    "    yResults = [item for sublist in yResults_all for item in sublist]\n",
    "    zResults = [item for sublist in zResults_all for item in sublist]\n",
    "    magResults = [item for sublist in magResults_all for item in sublist]\n",
    "    combineResults = [item for sublist in combineResults_all for item in sublist]\n",
    "    xnResults = [item for sublist in xResults_all_noise for item in sublist]\n",
    "    ynResults = [item for sublist in yResults_all_noise for item in sublist]\n",
    "    znResults = [item for sublist in zResults_all_noise for item in sublist]\n",
    "    magnResults = [item for sublist in magResults_all_noise for item in sublist]\n",
    "    combinenResults = [item for sublist in combineResults_all_noise for item in sublist]\n",
    "    plot_distribution(ax1, xResults, 10, None, \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query X Distribution\")\n",
    "    plot_distribution(ax1, queryX_all, 10, None, \"green\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query X Distribution\")\n",
    "    plot_distribution(ax1, queryX_all_noise, 10, None, \"red\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query X Distribution\")\n",
    "    plot_distribution(ax2, yResults, 10, None, \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Y Distribution\")\n",
    "    plot_distribution(ax2, queryY_all, 10, None, \"green\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Y Distribution\")\n",
    "    plot_distribution(ax2, queryY_all_noise, 10, None, \"red\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Y Distribution\")\n",
    "    plot_distribution(ax3, zResults, 10, None, \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Z Distribution\")\n",
    "    plot_distribution(ax3, queryZ_all, 10, None, \"green\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Z Distribution\")\n",
    "    plot_distribution(ax3, queryZ_all_noise, 10, None, \"red\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Z Distribution\")\n",
    "    plot_distribution(ax4, magResults, 10, None, \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Combined Axes Magnitude\")\n",
    "    plot_distribution(ax4, queryMag_all, 10, None, \"green\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Combined Axes Magnitude\")\n",
    "    plot_distribution(ax4, queryMag_all_noise, 10, None, \"red\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Combined Axes Magnitude\")\n",
    "    plot_distribution(ax5, combineResults, 10, None, \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Combined Axes Magnitude 2\")\n",
    "    plot_distribution(ax5, queryCombine_all, 10, None, \"green\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Combined Axes Magnitude 2\")\n",
    "    plot_distribution(ax5, queryCombine_all_noise, 10, None, \"red\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Combined Axes Dot Product\")\n",
    "    \n",
    "    if NOISE_PERMUTATION:\n",
    "        plot_distribution(ax1, xnResults, 10, None, \"yellow\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query X Distribution\")\n",
    "        plot_distribution(ax2, ynResults, 10, None, \"yellow\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Y Distribution\")\n",
    "        plot_distribution(ax3, znResults, 10, None, \"yellow\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Z Distribution\")\n",
    "        plot_distribution(ax4, magnResults, 10, None, \"yellow\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Combined Axes Magnitude\")\n",
    "        plot_distribution(ax5, combinenResults, 10, None, \"yellow\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Combined Axes Projection\")\n",
    "    pplot.savefig(generate_filename(\"dist_comparison\")) if SAVE_FILES else pplot.show()\n",
    "    \n",
    "    rl = []\n",
    "\n",
    "    xrkde = univariate_kde(xResults)\n",
    "    xqkde = univariate_kde(queryX_all)\n",
    "    xnkde = univariate_kde(queryX_all_noise)\n",
    "    xqra = distribution_accuracy(xqkde, xrkde)\n",
    "    xqna = distribution_accuracy(xqkde, xnkde)\n",
    "    rl.append((\"X-axis\", xqra[0], xqra[1], xqra[2], xqna[0], xqna[1], xqna[2]))\n",
    "\n",
    "    yrkde = univariate_kde(yResults)\n",
    "    yqkde = univariate_kde(queryY_all)\n",
    "    ynkde = univariate_kde(queryY_all_noise)\n",
    "    yqra = distribution_accuracy(yqkde, yrkde)\n",
    "    yqna = distribution_accuracy(yqkde, ynkde)\n",
    "    rl.append((\"Y-axis\", yqra[0], yqra[1], yqra[2], yqna[0], yqna[1], yqna[2]))\n",
    "\n",
    "    zrkde = univariate_kde(zResults)\n",
    "    zqkde = univariate_kde(queryZ_all)\n",
    "    znkde = univariate_kde(queryZ_all_noise)\n",
    "    zqra = distribution_accuracy(zqkde, zrkde)\n",
    "    zqna = distribution_accuracy(zqkde, znkde)\n",
    "    rl.append((\"Z-axis\", zqra[0], zqra[1], zqra[2], zqna[0], zqna[1], zqna[2]))\n",
    "\n",
    "    mrkde = univariate_kde(magResults)\n",
    "    mqkde = univariate_kde(queryMag_all)\n",
    "    mnkde = univariate_kde(queryMag_all_noise)\n",
    "    mqra = distribution_accuracy(mqkde, mrkde)\n",
    "    mqna = distribution_accuracy(mqkde, mnkde)\n",
    "    rl.append((\"Combined Magnitude\", mqra[0], mqra[1], mqra[2], mqna[0], mqna[1], mqna[2]))\n",
    "    \n",
    "    crkde = univariate_kde(combineResults)\n",
    "    cqkde = univariate_kde(queryCombine_all)\n",
    "    cnkde = univariate_kde(queryCombine_all_noise)\n",
    "    cqra = distribution_accuracy(cqkde, crkde)\n",
    "    cqna = distribution_accuracy(cqkde, cnkde)\n",
    "    rl.append((\"Combined Projection\", cqra[0], cqra[1], cqra[2], cqna[0], cqna[1], cqna[2]))\n",
    "\n",
    "    fs = \"{0:.5f}\"\n",
    "    print(\"error vs permutation test and noise\")\n",
    "    for r in rl:\n",
    "        print(r[0], \"pe\", fs.format(r[1]), \"pfp\", fs.format(r[2]), \"pfn\", fs.format(r[3]), \"ne\", fs.format(r[4]), \"nfp\", fs.format(r[5]), \"nfn\", fs.format(r[6]))\n",
    "        \n",
    "if not SAVE_FILES:\n",
    "    data_distribution_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def data_correlation_distribution():\n",
    "    ccX = []\n",
    "    ccY = []\n",
    "    ccZ = []\n",
    "    ccMag = []\n",
    "    ccXn = []\n",
    "    ccYn = []\n",
    "    ccZn = []\n",
    "    ccMagn = []\n",
    "    xResults_all = []\n",
    "    yResults_all = []\n",
    "    zResults_all = []\n",
    "    magResults_all = []\n",
    "    csvData = csvNoiseSensorData\n",
    "    valueX = []\n",
    "    valueY = []\n",
    "    valueZ = []\n",
    "    valueMag = []\n",
    "    leftEvents = []\n",
    "    rightEvents = []\n",
    "    sensorDataLength = len(csvData['sensor'])\n",
    "    startIndex = 0\n",
    "    endIndex = sensorDataLength\n",
    "    for rowI in range(startIndex, endIndex):\n",
    "        row = csvData['sensor'][rowI]\n",
    "        if row == PLOT_SENSOR:\n",
    "            x = csvData['x'][rowI]\n",
    "            y = csvData['y'][rowI]\n",
    "            z = csvData['z'][rowI]\n",
    "            t = csvData['time'][rowI]\n",
    "            valueX.append((t, x))\n",
    "            valueY.append((t, y))\n",
    "            valueZ.append((t, z))\n",
    "            valueMag.append((t, mag(x, y, z)))\n",
    "        elif row == 'left':\n",
    "            leftEvents.append(csvData['time'][rowI])\n",
    "        elif row == 'right':\n",
    "            rightEvents.append(csvData['time'][rowI])\n",
    "    valueX = np.array(valueX)\n",
    "    valueY = np.array(valueY)\n",
    "    valueZ = np.array(valueZ)\n",
    "    valueMag = np.array(valueMag)\n",
    "    signalPeriod = rightEvents[1] - rightEvents[0]\n",
    "    defaultDuty = [(1,0)] * pairNum\n",
    "    referenceDuty = lambda x : duty_function_permutation(reduce(lambda x, y : x + y, defaultDuty), int(x.size / (pairNum * 2)))\n",
    "    referenceSignal = lambda x : signal.square((2*np.pi/signalPeriod)*x + (1.57079633 - (2*np.pi/signalPeriod)*leftEvents[0]), duty=referenceDuty(x)) if FIT_SQUARE else np.sin((2*np.pi/signalPeriod)*x + (1.57079633 - (2*np.pi/signalPeriod)*leftEvents[0])) # arcsin(1)\n",
    "    windowTime = signalPeriod * pairNum\n",
    "    dutyPermutes = [reduce(lambda x, y : x + y, r) for r in comboIterator(defaultDuty)]\n",
    "    for rowI in range(len(leftEvents) - pairNum):\n",
    "        startWindow = leftEvents[rowI]\n",
    "        endWindow = leftEvents[rowI + pairNum]\n",
    "        windowX = []\n",
    "        windowY = []\n",
    "        windowZ = []\n",
    "        windowMag = []\n",
    "        for v in valueX:\n",
    "            valueTime = v[0]\n",
    "            if valueTime >= startWindow and valueTime <= endWindow:\n",
    "                windowX.append(v)\n",
    "        for v in valueY:\n",
    "            valueTime = v[0]\n",
    "            if valueTime >= startWindow and valueTime <= endWindow:\n",
    "                windowY.append(v)\n",
    "        for v in valueZ:\n",
    "            valueTime = v[0]\n",
    "            if valueTime >= startWindow and valueTime <= endWindow:\n",
    "                windowZ.append(v)\n",
    "        for v in valueMag:\n",
    "            valueTime = v[0]\n",
    "            if valueTime >= startWindow and valueTime <= endWindow:\n",
    "                windowMag.append(v)\n",
    "        windowX = np.array(windowX)\n",
    "        windowY = np.array(windowY)\n",
    "        windowZ = np.array(windowZ)\n",
    "        windowMag = np.array(windowMag)\n",
    "        signal_range = windowX[:,0]\n",
    "        repeats = int(signal_range.size / (pairNum * 2))\n",
    "        slength = repeats * pairNum * 2\n",
    "        signal_range = signal_range[:slength]\n",
    "        generatedSignal = referenceSignal(signal_range)\n",
    "        actualSignalX = remove_trend(windowX[:,1][:slength])\n",
    "        actualSignalY = remove_trend(windowY[:,1][:slength])\n",
    "        actualSignalZ = remove_trend(windowZ[:,1][:slength])\n",
    "        actualSignalMag = remove_trend(windowMag[:,1][:slength])\n",
    "        if CORRELATION_EWMA:\n",
    "            actualSignalX = get_ewma(actualSignalX, alpha=0.1)\n",
    "            actualSignalY = get_ewma(actualSignalY, alpha=0.1)\n",
    "            actualSignalZ = get_ewma(actualSignalZ, alpha=0.1)\n",
    "            actualSignalMag = get_ewma(actualSignalMag, alpha=0.1)\n",
    "        rfactor = signal_range.size * 2\n",
    "        rs2 = resample(generatedSignal, rfactor, t=signal_range)\n",
    "        ps2x = resample(actualSignalX, rfactor, t=signal_range)[0]\n",
    "        ps2y = resample(actualSignalY, rfactor, t=signal_range)[0]\n",
    "        ps2z = resample(actualSignalZ, rfactor, t=signal_range)[0]\n",
    "        ps2m = resample(actualSignalMag, rfactor, t=signal_range)[0]\n",
    "        ts2 = rs2[1]\n",
    "        rs2 = rs2[0]\n",
    "        resample_time = (signal_range[-1] - signal_range[0]) / rfactor\n",
    "        lag_factorx = find_timeshift(rs2, ps2x)\n",
    "        lag_timex = resample_time * lag_factorx\n",
    "        generatedSignalx = signal.square((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_timex))) if FIT_SQUARE else np.sin((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_timex))) # arcsin(1)\n",
    "        lag_factory = find_timeshift(rs2, ps2y)\n",
    "        lag_timey = resample_time * lag_factory\n",
    "        generatedSignaly = signal.square((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_timey))) if FIT_SQUARE else np.sin((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_timey))) # arcsin(1)\n",
    "        lag_factorz = find_timeshift(rs2, ps2z)\n",
    "        lag_timez = resample_time * lag_factorz\n",
    "        generatedSignalz = signal.square((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_timez))) if FIT_SQUARE else np.sin((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_timez))) # arcsin(1)\n",
    "        lag_factorm = find_timeshift(rs2, ps2m)\n",
    "        lag_timem = resample_time * lag_factorm\n",
    "        generatedSignalm = signal.square((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_timem))) if FIT_SQUARE else np.sin((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_timem))) # arcsin(1)\n",
    "        ccXn.append(pearsonr(generatedSignalx, actualSignalX))\n",
    "        ccYn.append(pearsonr(generatedSignaly, actualSignalY))\n",
    "        ccZn.append(pearsonr(generatedSignalz, actualSignalZ))\n",
    "        ccMagn.append(pearsonr(generatedSignalm, actualSignalMag))\n",
    "    \n",
    "    csvData = csvSensorData\n",
    "    valueX = []\n",
    "    valueY = []\n",
    "    valueZ = []\n",
    "    valueMag = []\n",
    "    leftEvents = []\n",
    "    rightEvents = []\n",
    "    sensorDataLength = len(csvData['sensor'])\n",
    "    startIndex = 0\n",
    "    endIndex = sensorDataLength\n",
    "    for rowI in range(startIndex, endIndex):\n",
    "        row = csvData['sensor'][rowI]\n",
    "        if row == PLOT_SENSOR:\n",
    "            x = csvData['x'][rowI]\n",
    "            y = csvData['y'][rowI]\n",
    "            z = csvData['z'][rowI]\n",
    "            t = csvData['time'][rowI]\n",
    "            valueX.append((t, x))\n",
    "            valueY.append((t, y))\n",
    "            valueZ.append((t, z))\n",
    "            valueMag.append((t, mag(x, y, z)))\n",
    "        elif row == 'left':\n",
    "            leftEvents.append(csvData['time'][rowI])\n",
    "        elif row == 'right':\n",
    "            rightEvents.append(csvData['time'][rowI])\n",
    "    valueX = np.array(valueX)\n",
    "    valueY = np.array(valueY)\n",
    "    valueZ = np.array(valueZ)\n",
    "    valueMag = np.array(valueMag)\n",
    "    windowTime = signalPeriod * pairNum\n",
    "    for rowI in range(len(leftEvents) - pairNum):\n",
    "        startWindow = leftEvents[rowI]\n",
    "        endWindow = leftEvents[rowI + pairNum]\n",
    "        windowX = []\n",
    "        windowY = []\n",
    "        windowZ = []\n",
    "        windowMag = []\n",
    "        for v in valueX:\n",
    "            valueTime = v[0]\n",
    "            if valueTime >= startWindow and valueTime <= endWindow:\n",
    "                windowX.append(v)\n",
    "        for v in valueY:\n",
    "            valueTime = v[0]\n",
    "            if valueTime >= startWindow and valueTime <= endWindow:\n",
    "                windowY.append(v)\n",
    "        for v in valueZ:\n",
    "            valueTime = v[0]\n",
    "            if valueTime >= startWindow and valueTime <= endWindow:\n",
    "                windowZ.append(v)\n",
    "        for v in valueMag:\n",
    "            valueTime = v[0]\n",
    "            if valueTime >= startWindow and valueTime <= endWindow:\n",
    "                windowMag.append(v)\n",
    "        windowX = np.array(windowX)\n",
    "        windowY = np.array(windowY)\n",
    "        windowZ = np.array(windowZ)\n",
    "        windowMag = np.array(windowMag)\n",
    "        signal_range = windowX[:,0]\n",
    "        repeats = int(signal_range.size / (pairNum * 2))\n",
    "        slength = repeats * pairNum * 2\n",
    "        signal_range = signal_range[:slength]\n",
    "        generatedSignal = referenceSignal(signal_range)\n",
    "        actualSignalX = remove_trend(windowX[:,1][:slength])\n",
    "        actualSignalY = remove_trend(windowY[:,1][:slength])\n",
    "        actualSignalZ = remove_trend(windowZ[:,1][:slength])\n",
    "        actualSignalMag = remove_trend(windowMag[:,1][:slength])\n",
    "        dfuncs = [duty_function_permutation(d, repeats) for d in dutyPermutes]\n",
    "        \n",
    "        if CORRELATION_EWMA:\n",
    "            actualSignalX = get_ewma(actualSignalX, alpha=0.1)\n",
    "            actualSignalY = get_ewma(actualSignalY, alpha=0.1)\n",
    "            actualSignalZ = get_ewma(actualSignalZ, alpha=0.1)\n",
    "            actualSignalMag = get_ewma(actualSignalMag, alpha=0.1)\n",
    "        rfactor = signal_range.size * 2\n",
    "        rs2 = resample(generatedSignal, rfactor, t=signal_range)\n",
    "        ps2x = resample(actualSignalX, rfactor, t=signal_range)[0]\n",
    "        ps2y = resample(actualSignalY, rfactor, t=signal_range)[0]\n",
    "        ps2z = resample(actualSignalZ, rfactor, t=signal_range)[0]\n",
    "        ps2m = resample(actualSignalMag, rfactor, t=signal_range)[0]\n",
    "        ts2 = rs2[1]\n",
    "        rs2 = rs2[0]\n",
    "        resample_time = (signal_range[-1] - signal_range[0]) / rfactor\n",
    "        df = referenceDuty(signal_range)\n",
    "        lag_factorx = find_timeshift(rs2, ps2x)\n",
    "        lag_timex = resample_time * lag_factorx\n",
    "        generatedSignalx = signal.square((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_timex)), duty=df) if FIT_SQUARE else np.sin((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_timex))) # arcsin(1)\n",
    "        lag_factory = find_timeshift(rs2, ps2y)\n",
    "        lag_timey = resample_time * lag_factory\n",
    "        generatedSignaly = signal.square((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_timey)), duty=df) if FIT_SQUARE else np.sin((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_timey))) # arcsin(1)\n",
    "        lag_factorz = find_timeshift(rs2, ps2z)\n",
    "        lag_timez = resample_time * lag_factorz\n",
    "        generatedSignalz = signal.square((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_timez)), duty=df) if FIT_SQUARE else np.sin((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_timez))) # arcsin(1)\n",
    "        lag_factorm = find_timeshift(rs2, ps2m)\n",
    "        lag_timem = resample_time * lag_factorm\n",
    "        generatedSignalm = signal.square((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_timem)), duty=df) if FIT_SQUARE else np.sin((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_timem))) # arcsin(1)\n",
    "        ccX.append(pearsonr(generatedSignalx, actualSignalX))\n",
    "        ccY.append(pearsonr(generatedSignaly, actualSignalY))\n",
    "        ccZ.append(pearsonr(generatedSignalz, actualSignalZ))\n",
    "        ccMag.append(pearsonr(generatedSignalm, actualSignalMag))\n",
    "        for df in dfuncs:\n",
    "            gsx = signal.square((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_timex)), duty=df)\n",
    "            gsy = signal.square((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_timey)), duty=df)\n",
    "            gsz = signal.square((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_timez)), duty=df)\n",
    "            gsm = signal.square((2*np.pi/signalPeriod)*signal_range + (1.57079633 - (2*np.pi/signalPeriod)*(leftEvents[0]+lag_timem)), duty=df)\n",
    "            xResults_all.append(pearsonr(gsx, actualSignalX))\n",
    "            yResults_all.append(pearsonr(gsy, actualSignalY))\n",
    "            zResults_all.append(pearsonr(gsz, actualSignalZ))\n",
    "            magResults_all.append(pearsonr(gsm, actualSignalMag))\n",
    "            if SHOW_CORRELATION_WINDOWS:\n",
    "                pplot.clf()\n",
    "                pplot.plot(signal_range, actualSignalX,color=\"red\")\n",
    "                pplot.plot(signal_range, gsx,color=\"green\")\n",
    "                pplot.plot(signal_range, generatedSignalx,color=\"blue\")\n",
    "                pplot.show()\n",
    "            \n",
    "    \n",
    "    ccX = np.array(ccX)\n",
    "    ccY = np.array(ccY)\n",
    "    ccZ = np.array(ccZ)\n",
    "    ccMag = np.array(ccMag)\n",
    "    ccXn = np.array(ccXn)\n",
    "    ccYn = np.array(ccYn)\n",
    "    ccZn = np.array(ccZn)\n",
    "    ccMagn = np.array(ccMagn)\n",
    "    queryX_all = ccX[:,0]\n",
    "    queryY_all = ccY[:,0]\n",
    "    queryZ_all = ccZ[:,0]\n",
    "    queryMag_all = ccMag[:,0]\n",
    "    queryX_all_noise = ccXn[:,0]\n",
    "    queryY_all_noise = ccYn[:,0]\n",
    "    queryZ_all_noise = ccZn[:,0]\n",
    "    queryMag_all_noise = ccMagn[:,0]\n",
    "    pplot.clf()\n",
    "    f, (ax1, ax2, ax3, ax4) = pplot.subplots(4)\n",
    "    f.set_size_inches(FIGURE_SIZE)\n",
    "    xResults = [item for sublist in xResults_all for item in sublist]\n",
    "    yResults = [item for sublist in yResults_all for item in sublist]\n",
    "    zResults = [item for sublist in zResults_all for item in sublist]\n",
    "    magResults = [item for sublist in magResults_all for item in sublist]\n",
    "    plot_distribution(ax1, xResults, 10, None, \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query X Distribution\")\n",
    "    plot_distribution(ax1, xResults, 10, None, \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query X Distribution\")\n",
    "    plot_distribution(ax1, queryX_all, 10, None, \"green\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query X Distribution\")\n",
    "    plot_distribution(ax1, queryX_all_noise, 10, None, \"red\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query X Distribution\")\n",
    "    plot_distribution(ax2, yResults, 10, None, \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Y Distribution\")\n",
    "    plot_distribution(ax2, queryY_all, 10, None, \"green\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Y Distribution\")\n",
    "    plot_distribution(ax2, queryY_all_noise, 10, None, \"red\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Y Distribution\")\n",
    "    plot_distribution(ax3, zResults, 10, None, \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Z Distribution\")\n",
    "    plot_distribution(ax3, queryZ_all, 10, None, \"green\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Z Distribution\")\n",
    "    plot_distribution(ax3, queryZ_all_noise, 10, None, \"red\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Query Z Distribution\")\n",
    "    plot_distribution(ax4, magResults, 10, None, \"blue\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Combined Axes Magnitude\")\n",
    "    plot_distribution(ax4, queryMag_all, 10, None, \"green\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Combined Axes Magnitude\")\n",
    "    plot_distribution(ax4, queryMag_all_noise, 10, None, \"red\", xLabel=\"Mean\", yLabel=\"Density\", title=\"Combined Axes Magnitude\")\n",
    "    pplot.savefig(generate_filename(\"correlate_distribution\")) if SAVE_FILES else pplot.show()\n",
    "\n",
    "    \n",
    "    rl = []\n",
    "\n",
    "    xrkde = univariate_kde(xResults)\n",
    "    xqkde = univariate_kde(queryX_all)\n",
    "    xnkde = univariate_kde(queryX_all_noise)\n",
    "    xqra = distribution_accuracy(xqkde, xrkde)\n",
    "    xqna = distribution_accuracy(xqkde, xnkde)\n",
    "    rl.append((\"X-axis\", xqra[0], xqra[1], xqra[2], xqna[0], xqna[1], xqna[2]))\n",
    "\n",
    "    yrkde = univariate_kde(yResults)\n",
    "    yqkde = univariate_kde(queryY_all)\n",
    "    ynkde = univariate_kde(queryY_all_noise)\n",
    "    yqra = distribution_accuracy(yqkde, yrkde)\n",
    "    yqna = distribution_accuracy(yqkde, ynkde)\n",
    "    rl.append((\"Y-axis\", yqra[0], yqra[1], yqra[2], yqna[0], yqna[1], yqna[2]))\n",
    "\n",
    "    zrkde = univariate_kde(zResults)\n",
    "    zqkde = univariate_kde(queryZ_all)\n",
    "    znkde = univariate_kde(queryZ_all_noise)\n",
    "    zqra = distribution_accuracy(zqkde, zrkde)\n",
    "    zqna = distribution_accuracy(zqkde, znkde)\n",
    "    rl.append((\"Z-axis\", zqra[0], zqra[1], zqra[2], zqna[0], zqna[1], zqna[2]))\n",
    "\n",
    "    mrkde = univariate_kde(magResults)\n",
    "    mqkde = univariate_kde(queryMag_all)\n",
    "    mnkde = univariate_kde(queryMag_all_noise)\n",
    "    mqra = distribution_accuracy(mqkde, mrkde)\n",
    "    mqna = distribution_accuracy(mqkde, mnkde)\n",
    "    rl.append((\"Combined Magnitude\", mqra[0], mqra[1], mqra[2], mqna[0], mqna[1], mqna[2]))\n",
    "\n",
    "    fs = \"{0:.5f}\"\n",
    "    print(\"error vs permutation test and noise\")\n",
    "    for r in rl:\n",
    "        print(r[0], \"pe\", fs.format(r[1]), \"pfp\", fs.format(r[2]), \"pfn\", fs.format(r[3]), \"ne\", fs.format(r[4]), \"nfp\", fs.format(r[5]), \"nfn\", fs.format(r[6]))\n",
    "        \n",
    "if not SAVE_FILES:    \n",
    "    data_correlation_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_prefix():\n",
    "    global USE_DELTAS\n",
    "    global USE_STD_ALGORITHM\n",
    "    USE_DELTAS = False\n",
    "    USE_STD_ALGORITHM = False\n",
    "    data_plot_distribution()\n",
    "    data_plot_raw_data()\n",
    "    data_lag_calculation()\n",
    "    data_correlation_whole()\n",
    "    data_correlation_graphs()\n",
    "    data_online_performance()\n",
    "    data_distribution_comparison()\n",
    "    USE_DELTAS = True\n",
    "    USE_STD_ALGORITHM = False\n",
    "    data_plot_distribution()\n",
    "    data_plot_raw_data()\n",
    "    data_lag_calculation()\n",
    "    data_correlation_whole()\n",
    "    data_correlation_graphs()\n",
    "    data_online_performance()\n",
    "    data_distribution_comparison()\n",
    "    USE_DELTAS = False\n",
    "    USE_STD_ALGORITHM = True\n",
    "    data_plot_distribution()\n",
    "    data_plot_raw_data()\n",
    "    data_lag_calculation()\n",
    "    data_correlation_whole()\n",
    "    data_correlation_graphs()\n",
    "    data_online_performance()\n",
    "    data_distribution_comparison()\n",
    "    USE_DELTAS = True\n",
    "    USE_STD_ALGORITHM = True\n",
    "    data_plot_distribution()\n",
    "    data_plot_raw_data()\n",
    "    data_lag_calculation()\n",
    "    data_correlation_whole()\n",
    "    data_correlation_graphs()\n",
    "    data_online_performance()\n",
    "    data_distribution_comparison()\n",
    "\n",
    "if FILE_OUTPUT:\n",
    "    global SAVE_FILES\n",
    "    SAVE_FILES = True\n",
    "    prefixes = set([f[:f.index(\"_s\")] for f in os.listdir(CSV_PATH) if f.endswith(\".csv\") and not f.startswith(\".\")])\n",
    "    for p in prefixes:\n",
    "        global CSV_PREFIX\n",
    "        CSV_PREFIX = p\n",
    "        print(\"processing\", p)\n",
    "        initialize_environment()\n",
    "        process_prefix()\n",
    "        figure_dir = FOLDER_PREFIX + p\n",
    "        if not os.path.exists(figure_dir):\n",
    "            os.makedirs(figure_dir)\n",
    "        p_output = [FOLDER_PREFIX + f for f in os.listdir(FOLDER_PREFIX) if f.endswith(FILE_FORMAT)]\n",
    "        for o in p_output:\n",
    "            shutil.move(o, figure_dir)\n",
    "\n",
    "    SAVE_FILES = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
